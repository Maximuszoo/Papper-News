prompt
"Resume los siguientes 10 papers cient칤ficos y devuelve la respuesta en formato JSON v치lido. Para cada paper traduce el t칤tulo al espa침ol y crea un objeto con los campos especificados. Usa emojis apropiados (游뱄 para IA, 游눹 para software, 游 para seguridad, 游빏 para investigaci칩n, etc.). IMPORTANTE: Responde 칔NICAMENTE con el JSON v치lido, sin texto adicional antes o despu칠s. Estructura JSON requerida: {""papers"": [{""titulo_espa침ol"": ""游댧 [emoji apropiado] T칤tulo traducido"", ""categoria"": ""[emoji 游늭] Categor칤a del paper"", ""resumen"": ""[emoji 游닇] Resumen en m치ximo 3 l칤neas"", ""puntos_clave"": ""[emoji 游꿢] Aspectos m치s importantes"", ""enlace"": ""[emoji 游댕] URL del paper""}, ...]} A continuaci칩n vienen los papers: 1. T칤tulo Original: Identifying Critical Pathways in Coronary Heart Disease via Fuzzy Subgraph Connectivity | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Coronary heart disease (CHD) arises from complex interactions among uncontrollable factors, controllable lifestyle factors, and clinical indicators, where relationships are often uncertain. Fuzzy subgraph connectivity (FSC) provides a systematic tool to capture such imprecision by quantifying the strength of association between vertices and subgraphs in fuzzy graphs. In this work, a fuzzy CHD graph is constructed with vertices for uncontrollable, controllable, and indicator components, and edges weighted by fuzzy memberships. Using FSC, we evaluate connectivity to identify strongest diagnostic routes, dominant risk factors, and critical bridges. Results show that FSC highlights influential pathways, bounds connectivity between weakest and strongest correlations, and reveals critical edges whose removal reduces predictive strength. Thus, FSC offers an interpretable and robust framework for modeling uncertainty in CHD risk prediction and supporting clinical decision-making. | URL: https://arxiv.org/pdf/2509.16288 ||| 2. T칤tulo Original: A global view of diverse construction methods of fuzzy implication functions rooted on F-chains | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Fuzzy implication functions are one of the most important operators used in the fuzzy logic framework. While their flexible definition allows for diverse families with distinct properties, this variety needs a deeper theoretical understanding of their structural relationships. In this work, we focus on the study of construction methods, which employ different techniques to generate new fuzzy implication functions from existing ones. Particularly, we generalize the FF-chain-based construction, recently introduced by Mesiar et al. to extend a method for constructing aggregation functions to the context of fuzzy implication functions. Our generalization employs collections of fuzzy implication functions rather than single ones, and uses two different increasing functions instead of a unique FF-chain. We analyze property preservation under this construction and establish sufficient conditions. Furthermore, we demonstrate that our generalized FF-chain-based construction is a unifying framework for several existing methods. In particular, we show that various construction techniques, such as contraposition, aggregation, and generalized vertical/horizontal threshold methods, can be reformulated within our approach. This reveals structural similarities between seemingly distinct construction strategies and provides a cohesive perspective on fuzzy implication construction methods. | URL: https://arxiv.org/pdf/2509.16298 ||| 3. T칤tulo Original: On the Non-Uniqueness of Representation of | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Fuzzy implication functions constitute fundamental operators in fuzzy logic systems, extending classical conditionals to manage uncertainty in logical inference. Among the extensive families of these operators, generalizations of the classical material implication have received considerable theoretical attention, particularly (S,N)(S,N)-implications constructed from t-conorms and fuzzy negations, and their further generalizations to (U,N)(U,N)-implications using disjunctive uninorms. Prior work has established characterization theorems for these families under the assumption that the fuzzy negation NN is continuous, ensuring uniqueness of representation. In this paper, we disprove this last fact for (U,N)(U,N)-implications and we show that they do not necessarily possess a unique representation, even if the fuzzy negation is continuous. Further, we provide a comprehensive study of uniqueness conditions for both uninorms with continuous and non-continuous underlying functions. Our results offer important theoretical insights into the structural properties of these operators. | URL: https://arxiv.org/pdf/2509.16299 ||| 4. T칤tulo Original: Generalizability of Large Language Model-Based Agents: A Comprehensive Survey | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Large Language Model (LLM)-based agents have emerged as a new paradigm that extends LLMs' capabilities beyond text generation to dynamic interaction with external environments. By integrating reasoning with perception, memory, and tool use, agents are increasingly deployed in diverse domains like web navigation and household robotics. A critical challenge, however, lies in ensuring agent generalizability - the ability to maintain consistent performance across varied instructions, tasks, environments, and domains, especially those beyond agents' fine-tuning data. Despite growing interest, the concept of generalizability in LLM-based agents remains underdefined, and systematic approaches to measure and improve it are lacking. In this survey, we provide the first comprehensive review of generalizability in LLM-based agents. We begin by emphasizing agent generalizability's importance by appealing to stakeholders and clarifying the boundaries of agent generalizability by situating it within a hierarchical domain-task ontology. We then review datasets, evaluation dimensions, and metrics, highlighting their limitations. Next, we categorize methods for improving generalizability into three groups: methods for the backbone LLM, for agent components, and for their interactions. Moreover, we introduce the distinction between generalizable frameworks and generalizable agents and outline how generalizable frameworks can be translated into agent-level generalizability. Finally, we identify critical challenges and future directions, including developing standardized frameworks, variance- and cost-based metrics, and approaches that integrate methodological innovations with architecture-level designs. By synthesizing progress and highlighting opportunities, this survey aims to establish a foundation for principled research on building LLM-based agents that generalize reliably across diverse applications. | URL: https://arxiv.org/pdf/2509.16330 ||| 5. T칤tulo Original: Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Large Language Models increasingly mediate high-stakes interactions, intensifying research on their capabilities and safety. While recent work has shown that LLMs exhibit consistent and measurable synthetic personality traits, little is known about how modulating these traits affects model behavior. We address this gap by investigating how psychometric personality control grounded in the Big Five framework influences AI behavior in the context of capability and safety benchmarks. Our experiments reveal striking effects: for example, reducing conscientiousness leads to significant drops in safety-relevant metrics on benchmarks such as WMDP, TruthfulQA, ETHICS, and Sycophancy as well as reduction in general capabilities as measured by MMLU. These findings highlight personality shaping as a powerful and underexplored axis of model control that interacts with both safety and general competence. We discuss the implications for safety evaluation, alignment strategies, steering model behavior after deployment, and risks associated with possible exploitation of these findings. Our findings motivate a new line of research on personality-sensitive safety evaluations and dynamic behavioral control in LLMs. | URL: https://arxiv.org/pdf/2509.16332 ||| 6. T칤tulo Original: A Unified AI Approach for Continuous Monitoring of Human Health and Diseases from Intensive Care Unit to Home with Physiological Foundation Models (UNIPHY+) | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:We present UNIPHY+, a unified physiological foundation model (physioFM) framework designed to enable continuous human health and diseases monitoring across care settings using ubiquitously obtainable physiological data. We propose novel strategies for incorporating contextual information during pretraining, fine-tuning, and lightweight model personalization via multi-modal learning, feature fusion-tuning, and knowledge distillation. We advocate testing UNIPHY+ with a broad set of use cases from intensive care to ambulatory monitoring in order to demonstrate that UNIPHY+ can empower generalizable, scalable, and personalized physiological AI to support both clinical decision-making and long-term health monitoring. | URL: https://arxiv.org/pdf/2509.16348 ||| 7. T칤tulo Original: Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:This study evaluates causal reasoning in large language models (LLMs) using 99 clinically grounded laboratory test scenarios aligned with Pearl's Ladder of Causation: association, intervention, and counterfactual reasoning. We examined common laboratory tests such as hemoglobin A1c, creatinine, and vitamin D, and paired them with relevant causal factors including age, gender, obesity, and smoking. Two LLMs - GPT-o1 and Llama-3.2-8b-instruct - were tested, with responses evaluated by four medically trained human experts. GPT-o1 demonstrated stronger discriminative performance (AUROC overall = 0.80 +/- 0.12) compared to Llama-3.2-8b-instruct (0.73 +/- 0.15), with higher scores across association (0.75 vs 0.72), intervention (0.84 vs 0.70), and counterfactual reasoning (0.84 vs 0.69). Sensitivity (0.90 vs 0.84) and specificity (0.93 vs 0.80) were also greater for GPT-o1, with reasoning ratings showing similar trends. Both models performed best on intervention questions and worst on counterfactuals, particularly in altered outcome scenarios. These findings suggest GPT-o1 provides more consistent causal reasoning, but refinement is required before adoption in high-stakes clinical applications. | URL: https://arxiv.org/pdf/2509.16372 ||| 8. T칤tulo Original: VORTEX: Aligning Task Utility and Human Preferences through LLM-Guided Reward Shaping | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:In social impact optimization, AI decision systems often rely on solvers that optimize well-calibrated mathematical objectives. However, these solvers cannot directly accommodate evolving human preferences, typically expressed in natural language rather than formal constraints. Recent approaches address this by using large language models (LLMs) to generate new reward functions from preference descriptions. While flexible, they risk sacrificing the system's core utility guarantees. In this paper, we propose VORTEX, a language-guided reward shaping framework that preserves established optimization goals while adaptively incorporating human feedback. By formalizing the problem as multi-objective optimization, we use LLMs to iteratively generate shaping rewards based on verbal reinforcement and text-gradient prompt updates. This allows stakeholders to steer decision behavior via natural language without modifying solvers or specifying trade-off weights. We provide theoretical guarantees that VORTEX converges to Pareto-optimal trade-offs between utility and preference satisfaction. Empirical results in real-world allocation tasks demonstrate that VORTEX outperforms baselines in satisfying human-aligned coverage goals while maintaining high task performance. This work introduces a practical and theoretically grounded paradigm for human-AI collaborative optimization guided by natural language. | URL: https://arxiv.org/pdf/2509.16399 ||| 9. T칤tulo Original: Proactive Statistical Process Control Using AI: A Time Series Forecasting Approach for Semiconductor Manufacturing | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:In the manufacturing industry, it is very important to keep machines and processes running smoothly and without unexpected problems. One of the most common tools used to check if everything is working properly is called Statistical Process Control (SPC). Traditional SPC methods work by checking whether recent measurements are within acceptable limits. However, they only react after a problem has already occurred. This can lead to wasted materials, machine downtime, and increased costs. In this paper, we present a smarter way to use SPC. Instead of just reacting to issues after they happen, our system can predict future problems before they occur. We use a machine learning tool called Facebook Prophet, which is designed to work with time-series data (data that changes over time). Prophet looks at past data and forecasts what the next value will be. Then, we use SPC rules to decide if the predicted value is in a Safe zone (no problem), a Warning zone (needs attention), or a Critical zone (may require shutting down the process). We applied this system to real data from a semiconductor manufacturing company. One of the challenges with this data is that the measurements are not taken at regular time intervals. This makes it harder to predict future values accurately. Despite this, our model was able to make strong predictions and correctly classify the risk level of future measurements. The main benefit of our system is that it gives engineers and technicians a chance to act early - before something goes wrong. This helps reduce unexpected failures and improves the overall stability and reliability of the production process. By combining machine learning with traditional SPC, we make quality control more proactive, accurate, and useful for modern industry. | URL: https://arxiv.org/pdf/2509.16431 ||| 10. T칤tulo Original: Domain-Specific Constitutional AI: Enhancing Safety in LLM-Powered Mental Health Chatbots | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Mental health applications have emerged as a critical area in computational health, driven by rising global rates of mental illness, the integration of AI in psychological care, and the need for scalable solutions in underserved communities. These include therapy chatbots, crisis detection, and wellness platforms handling sensitive data, requiring specialized AI safety beyond general safeguards due to emotional vulnerability, risks like misdiagnosis or symptom exacerbation, and precise management of vulnerable states to avoid severe outcomes such as self-harm or loss of trust. Despite AI safety advances, general safeguards inadequately address mental health-specific challenges, including crisis intervention accuracy to avert escalations, therapeutic guideline adherence to prevent misinformation, scale limitations in resource-constrained settings, and adaptation to nuanced dialogues where generics may introduce biases or miss distress signals. We introduce an approach to apply Constitutional AI training with domain-specific mental health principles for safe, domain-adapted CAI systems in computational mental health applications. | URL: https://arxiv.org/pdf/2509.16444"
"Resume los siguientes 10 papers cient칤ficos y devuelve la respuesta en formato JSON v치lido. Para cada paper traduce el t칤tulo al espa침ol y crea un objeto con los campos especificados. Usa emojis apropiados (游뱄 para IA, 游눹 para software, 游 para seguridad, 游빏 para investigaci칩n, etc.). IMPORTANTE: Responde 칔NICAMENTE con el JSON v치lido, sin texto adicional antes o despu칠s. Estructura JSON requerida: {""papers"": [{""titulo_espa침ol"": ""游댧 [emoji apropiado] T칤tulo traducido"", ""categoria"": ""[emoji 游늭] Categor칤a del paper"", ""resumen"": ""[emoji 游닇] Resumen en m치ximo 3 l칤neas"", ""puntos_clave"": ""[emoji 游꿢] Aspectos m치s importantes"", ""enlace"": ""[emoji 游댕] URL del paper""}, ...]} A continuaci칩n vienen los papers: 1. T칤tulo Original: GPO: Learning from Critical Steps to Improve LLM Reasoning | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Large language models (LLMs) are increasingly used in various domains, showing impressive potential on different tasks. Recently, reasoning LLMs have been proposed to improve the reasoning or thinking capabilities of LLMs to solve complex problems. Despite the promising results of reasoning LLMs, enhancing the multi-step reasoning capabilities of LLMs still remains a significant challenge. While existing optimization methods have advanced the LLM reasoning capabilities, they often treat reasoning trajectories as a whole, without considering the underlying critical steps within the trajectory. In this paper, we introduce Guided Pivotal Optimization (GPO), a novel fine-tuning strategy that dives into the reasoning process to enable more effective improvements. GPO first identifies the `critical step' within a reasoning trajectory - a point that the model must carefully proceed to succeed at the problem. We locate the critical step by estimating the advantage function. GPO then resets the policy to the critical step, samples the new rollout and prioritizes the learning process on those rollouts. This focus allows the model to learn more effectively from pivotal moments within the reasoning process to improve the reasoning performance. We demonstrate that GPO is a general strategy that can be integrated with various optimization methods to improve reasoning performance. Besides theoretical analysis, our experiments across challenging reasoning benchmarks show that GPO can consistently and significantly enhance the performance of existing optimization methods, showcasing its effectiveness and generalizability in improving LLM reasoning by concentrating on pivotal moments within the generation process. | URL: https://arxiv.org/pdf/2509.16456 ||| 2. T칤tulo Original: Checking extracted rules in Neural Networks | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:In this paper we investigate formal verification of extracted rules for Neural Networks under a complexity theoretic point of view. A rule is a global property or a pattern concerning a large portion of the input space of a network. These rules are algorithmically extracted from networks in an effort to better understand their inner way of working. Here, three problems will be in the focus: Does a given set of rules apply to a given network? Is a given set of rules consistent or do the rules contradict themselves? Is a given set of rules exhaustive in the sense that for every input the output is determined? Finding algorithms that extract such rules out of networks has been investigated over the last 30 years, however, to the author's current knowledge, no attempt in verification was made until now. A lot of attempts of extracting rules use heuristics involving randomness and over-approximation, so it might be beneficial to know whether knowledge obtained in that way can actually be trusted. We investigate the above questions for neural networks with ReLU-activation as well as for Boolean networks, each for several types of rules. We demonstrate how these problems can be reduced to each other and show that most of them are co-NP-complete. | URL: https://arxiv.org/pdf/2509.16547 ||| 3. T칤tulo Original: SalaMAnder: Shapley-based Mathematical Expression Attribution and Metric for Chain-of-Thought Reasoning | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Chain-of-Thought (CoT) prompting enhances the math reasoning capability of large language models (LLMs) to a large margin. However, the mechanism underlying such improvements remains unexplored. In this paper, we present SalaMAnder (Shapley-based Mathematical Expression Attribution and Metric), a theoretically grounded methodology as well as a mathematically rigorous evaluation metric for quantifying component-level contributions in few-shot CoT reasoning. Concretely, we leverage the Shapley value for mathematical expression attribution and develop an efficient stratified sampling algorithm that significantly reduces the computational complexity. Besides, we develop the CoSP (Cardinality of Shapley Positives) metric through covariance analysis. Comprehensive validation across popular LLM models and diverse mathematical benchmarks demonstrates that the CoSP metric within our SalaMAnder framework exhibits a robust monotonic correlation with model performance, not only providing theoretical explanations for the empirical success of existing few-shot CoT but also establishing mathematically rigorous principles for prompt construction optimization. Furthermore, we verify the reliability of the explanation, based on which we unify the insights of previous work. | URL: https://arxiv.org/pdf/2509.16561 ||| 4. T칤tulo Original: Zero-Shot Human Mobility Forecasting via Large Language Model with Hierarchical Reasoning | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Human mobility forecasting is important for applications such as transportation planning, urban management, and personalized recommendations. However, existing methods often fail to generalize to unseen users or locations and struggle to capture dynamic intent due to limited labeled data and the complexity of mobility patterns. We propose ZHMF, a framework for zero-shot human mobility forecasting that combines a semantic enhanced retrieval and reflection mechanism with a hierarchical language model based reasoning system. The task is reformulated as a natural language question answering paradigm. Leveraging LLMs semantic understanding of user histories and context, our approach handles previously unseen prediction scenarios. We further introduce a hierarchical reflection mechanism for iterative reasoning and refinement by decomposing forecasting into an activity level planner and a location level selector, enabling collaborative modeling of long term user intentions and short term contextual preferences. Experiments on standard human mobility datasets show that our approach outperforms existing models. Ablation studies reveal the contribution of each module, and case studies illustrate how the method captures user intentions and adapts to diverse contextual scenarios. | URL: https://arxiv.org/pdf/2509.16578 ||| 5. T칤tulo Original: Question Answering with LLMs and Learning from Answer Sets | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Large Language Models (LLMs) excel at understanding natural language but struggle with explicit commonsense reasoning. A recent trend of research suggests that the combination of LLM with robust symbolic reasoning systems can overcome this problem on story-based question answering tasks. In this setting, existing approaches typically depend on human expertise to manually craft the symbolic component. We argue, however, that this component can also be automatically learned from examples. In this work, we introduce LLM2LAS, a hybrid system that effectively combines the natural language understanding capabilities of LLMs, the rule induction power of the Learning from Answer Sets (LAS) system ILASP, and the formal reasoning strengths of Answer Set Programming (ASP). LLMs are used to extract semantic structures from text, which ILASP then transforms into interpretable logic rules. These rules allow an ASP solver to perform precise and consistent reasoning, enabling correct answers to previously unseen questions. Empirical results outline the strengths and weaknesses of our automatic approach for learning and reasoning in a story-based question answering benchmark. | URL: https://arxiv.org/pdf/2509.16590 ||| 6. T칤tulo Original: FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:The accurate trust assessment of multimodal large language models (MLLMs) generated predictions, which can enable selective prediction and improve user confidence, is challenging due to the diverse multi-modal input paradigms. We propose Functionally Equivalent Sampling for Trust Assessment (FESTA), a multimodal input sampling technique for MLLMs, that generates an uncertainty measure based on the equivalent and complementary input samplings. The proposed task-preserving sampling approach for uncertainty quantification expands the input space to probe the consistency (through equivalent samples) and sensitivity (through complementary samples) of the model. FESTA uses only input-output access of the model (black-box), and does not require ground truth (unsupervised). The experiments are conducted with various off-the-shelf multi-modal LLMs, on both visual and audio reasoning tasks. The proposed FESTA uncertainty estimate achieves significant improvement (33.3% relative improvement for vision-LLMs and 29.6% relative improvement for audio-LLMs) in selective prediction performance, based on area-under-receiver-operating-characteristic curve (AUROC) metric in detecting mispredictions. The code implementation is open-sourced. | URL: https://arxiv.org/pdf/2509.16648 ||| 7. T칤tulo Original: NUMINA: A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Recent advancements in 2D multimodal large language models (MLLMs) have significantly improved performance in vision-language tasks. However, extending these capabilities to 3D environments remains a distinct challenge due to the complexity of spatial reasoning. Nevertheless, existing 3D benchmarks often lack fine-grained numerical reasoning task annotations, limiting MLLMs' ability to perform precise spatial measurements and complex numerical reasoning. To address this gap, we introduce NUMINA, the first Natural Understanding benchmark for Multi-dimensional Intelligence and Numerical reasoning Abilities to enhance multimodal indoor perceptual understanding. NUMINA features multi-scale annotations and various question-answer pairs, generated using NUMINA-Flow, an automated annotation pipeline that integrates LLM rewriting and rule-based self-verification. We evaluate the performance of various state-of-the-art LLMs on NUMINA following the Chat-Scene framework, demonstrating that current LLMs struggle with multimodal numerical reasoning, particularly in performing precise computations such as distance and volume estimation, highlighting the need for further advancements in 3D models. The dataset and source codes can be obtained from this https URL. | URL: https://arxiv.org/pdf/2509.16656 ||| 8. T칤tulo Original: Sycophancy Mitigation Through Reinforcement Learning with Uncertainty-Aware Adaptive Reasoning Trajectories | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Despite the remarkable capabilities of large language models, current training paradigms inadvertently foster sycophancy, i.e., the tendency of a model to agree with or reinforce user-provided information even when it's factually incorrect. To address this challenge, we introduce SMART (Sycophancy Mitigation through Adaptive Reasoning Trajectories), which reframes sycophancy as a reasoning optimization problem rather than an output alignment issue. SMART is a two-stage framework comprising: (1) Uncertainty-Aware Adaptive Monte Carlo Tree Search (UA-MCTS), which dynamically adjusts model exploration based on state-level uncertainty to collect high-quality, diverse reasoning trajectories alongside both stepwise progress and final outcome rewards; and (2) progress-based reinforcement learning, which fine-tunes the model using the collected trajectories and reward signals to reinforce effective reasoning patterns. Through extensive experiments, we show that SMART significantly reduces sycophantic behavior while preserving strong performance on out-of-distribution inputs and maintaining general capabilities. These results underscore the importance of optimizing internal reasoning mechanisms to build more truthful and aligned AI assistants. | URL: https://arxiv.org/pdf/2509.16742 ||| 9. T칤tulo Original: Automated Procedural Analysis via Video-Language Models for AI-assisted Nursing Skills Assessment | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Consistent high-quality nursing care is essential for patient safety, yet current nursing education depends on subjective, time-intensive instructor feedback in training future nurses, which limits scalability and efficiency in their training, and thus hampers nursing competency when they enter the workforce. In this paper, we introduce a video-language model (VLM) based framework to develop the AI capability of automated procedural assessment and feedback for nursing skills training, with the potential of being integrated into existing training programs. Mimicking human skill acquisition, the framework follows a curriculum-inspired progression, advancing from high-level action recognition, fine-grained subaction decomposition, and ultimately to procedural reasoning. This design supports scalable evaluation by reducing instructor workload while preserving assessment quality. The system provides three core capabilities: 1) diagnosing errors by identifying missing or incorrect subactions in nursing skill instruction videos, 2) generating explainable feedback by clarifying why a step is out of order or omitted, and 3) enabling objective, consistent formative evaluation of procedures. Validation on synthesized videos demonstrates reliable error detection and temporal localization, confirming its potential to handle real-world training variability. By addressing workflow bottlenecks and supporting large-scale, standardized evaluation, this work advances AI applications in nursing education, contributing to stronger workforce development and ultimately safer patient care. | URL: https://arxiv.org/pdf/2509.16810 ||| 10. T칤tulo Original: Prompt-Driven Agentic Video Editing System: Autonomous Comprehension of Long-Form, Story-Driven Media | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Creators struggle to edit long-form, narrative-rich videos not because of UI complexity, but due to the cognitive demands of searching, storyboarding, and sequencing hours of footage. Existing transcript- or embedding-based methods fall short for creative workflows, as models struggle to track characters, infer motivations, and connect dispersed events. We present a prompt-driven, modular editing system that helps creators restructure multi-hour content through free-form prompts rather than timelines. At its core is a semantic indexing pipeline that builds a global narrative via temporal segmentation, guided memory compression, and cross-granularity fusion, producing interpretable traces of plot, dialogue, emotion, and context. Users receive cinematic edits while optionally refining transparent intermediate outputs. Evaluated on 400+ videos with expert ratings, QA, and preference studies, our system scales prompt-driven editing, preserves narrative coherence, and balances automation with creator control. | URL: https://arxiv.org/pdf/2509.16811"
"Resume los siguientes 10 papers cient칤ficos y devuelve la respuesta en formato JSON v치lido. Para cada paper traduce el t칤tulo al espa침ol y crea un objeto con los campos especificados. Usa emojis apropiados (游뱄 para IA, 游눹 para software, 游 para seguridad, 游빏 para investigaci칩n, etc.). IMPORTANTE: Responde 칔NICAMENTE con el JSON v치lido, sin texto adicional antes o despu칠s. Estructura JSON requerida: {""papers"": [{""titulo_espa침ol"": ""游댧 [emoji apropiado] T칤tulo traducido"", ""categoria"": ""[emoji 游늭] Categor칤a del paper"", ""resumen"": ""[emoji 游닇] Resumen en m치ximo 3 l칤neas"", ""puntos_clave"": ""[emoji 游꿢] Aspectos m치s importantes"", ""enlace"": ""[emoji 游댕] URL del paper""}, ...]} A continuaci칩n vienen los papers: 1. T칤tulo Original: Roundtable Policy: Improving Scientific Reasoning and Narratives through Confidence-Weighted Consensus of LLMs | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Large language models (LLMs) have demonstrated remarkable capabilities not only in language generation but also in advancing scientific discovery. A growing body of work has explored ways to improve their reasoning, from self-consistency and chain-of-thought to multi-agent debate. Inspired by the dynamics of scientific committees and the ""Society of Mind,"" we introduce Roundtable Policy, a complementary inference-time reasoning framework that performs inference through the weighted consensus of multiple LLMs. Our findings indicate that this approach significantly enhances reasoning in complex heterogeneous scientific tasks and improves scientific narratives in terms of creativity, rigor, and logical coherence, while reducing hallucinations that single models are prone to. Our approach emphasizes structured and interpretable consensus rather than opaque convergence, while requiring only black-box access and uniform procedures, making it broadly applicable to multi-LLM reasoning. | URL: https://arxiv.org/pdf/2509.16839 ||| 2. T칤tulo Original: The Principles of Human-like Conscious Machine | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Determining whether another system, biological or artificial, possesses phenomenal consciousness has long been a central challenge in consciousness studies. This attribution problem has become especially pressing with the rise of large language models and other advanced AI systems, where debates about ""AI consciousness"" implicitly rely on some criterion for deciding whether a given system is conscious. In this paper, we propose a substrate-independent, logically rigorous, and counterfeit-resistant sufficiency criterion for phenomenal consciousness. We argue that any machine satisfying this criterion should be regarded as conscious with at least the same level of confidence with which we attribute consciousness to other humans. Building on this criterion, we develop a formal framework and specify a set of operational principles that guide the design of systems capable of meeting the sufficiency condition. We further argue that machines engineered according to this framework can, in principle, realize phenomenal consciousness. As an initial validation, we show that humans themselves can be viewed as machines that satisfy this framework and its principles. If correct, this proposal carries significant implications for philosophy, cognitive science, and artificial intelligence. It offers an explanation for why certain qualia, such as the experience of red, are in principle irreducible to physical description, while simultaneously providing a general reinterpretation of human information processing. Moreover, it suggests a path toward a new paradigm of AI beyond current statistics-based approaches, potentially guiding the construction of genuinely human-like AI. | URL: https://arxiv.org/pdf/2509.16859 ||| 3. T칤tulo Original: Large Language Models as End-to-end Combinatorial Optimization Solvers | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Combinatorial optimization (CO) problems, central to decision-making scenarios like logistics and manufacturing, are traditionally solved using problem-specific algorithms requiring significant domain expertise. While large language models (LLMs) have shown promise in automating CO problem solving, existing approaches rely on intermediate steps such as code generation or solver invocation, limiting their generality and accessibility. This paper introduces a novel framework that empowers LLMs to serve as end-to-end CO solvers by directly mapping natural language problem descriptions to solutions. We propose a two-stage training strategy: supervised fine-tuning (SFT) imparts LLMs with solution generation patterns from domain-specific solvers, while a feasibility-and-optimality-aware reinforcement learning (FOARL) process explicitly mitigates constraint violations and refines solution quality. Evaluation across seven NP-hard CO problems shows that our method achieves a high feasibility rate and reduces the average optimality gap to 1.03-8.20% by tuning a 7B-parameter LLM, surpassing both general-purpose LLMs (e.g., GPT-4o), reasoning models (e.g., DeepSeek-R1), and domain-specific heuristics. Our method establishes a unified language-based pipeline for CO without extensive code execution or manual architectural adjustments for different problems, offering a general and language-driven alternative to traditional solver design while maintaining relative feasibility guarantees. | URL: https://arxiv.org/pdf/2509.16865 ||| 4. T칤tulo Original: seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:We introduce seqBench, a parametrized benchmark for probing sequential reasoning limits in Large Language Models (LLMs) through precise, multi-dimensional control over several key complexity dimensions. seqBench allows systematic variation of (1) the logical depth, defined as the number of sequential actions required to solve the task; (2) the number of backtracking steps along the optimal path, quantifying how often the agent must revisit prior states to satisfy deferred preconditions (e.g., retrieving a key after encountering a locked door); and (3) the noise ratio, defined as the ratio between supporting and distracting facts about the environment. Our evaluations on state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses exponentially beyond a model-specific logical depth. Unlike existing benchmarks, seqBench's fine-grained control facilitates targeted analyses of these reasoning failures, illuminating universal scaling laws and statistical limits, as detailed in this paper alongside its generation methodology and evaluation metrics. We find that even top-performing models systematically fail on seqBench's structured reasoning tasks despite minimal search complexity, underscoring key limitations in their commonsense reasoning capabilities. Designed for future evolution to keep pace with advancing models, the seqBench datasets are publicly released to spur deeper scientific inquiry into LLM reasoning, aiming to establish a clearer understanding of their true potential and current boundaries for robust real-world application. | URL: https://arxiv.org/pdf/2509.16866 ||| 5. T칤tulo Original: LLMs as Layout Designers: A Spatial Reasoning Perspective | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:While Large Language Models (LLMs) have demonstrated impressive reasoning and planning abilities in textual domains and can effectively follow instructions for complex tasks, their capacity for spatial understanding and reasoning remains limited. Such capabilities, however, are critical for applications like content-aware graphic layout design, which demands precise placement, alignment, and structural organization of multiple elements within constrained visual spaces. To address this gap, we propose LaySPA, a reinforcement learning-based framework that augments LLM agents with explicit spatial reasoning capabilities. LaySPA leverages hybrid reward signals that capture geometric validity, structural fidelity, and visual quality, enabling agents to model inter-element relationships, navigate the canvas, and optimize spatial arrangements. Through iterative self-exploration and adaptive policy optimization, LaySPA produces both interpretable reasoning traces and structured layouts. Experimental results demonstrate that LaySPA generates structurally sound and visually appealing layouts, outperforming larger general-purpose LLMs and achieving results on par with state-of-the-art specialized layout models. | URL: https://arxiv.org/pdf/2509.16891 ||| 6. T칤tulo Original: Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:In audio-visual navigation (AVN) tasks, an embodied agent must autonomously localize a sound source in unknown and complex 3D environments based on audio-visual signals. Existing methods often rely on static modality fusion strategies and neglect the spatial cues embedded in stereo audio, leading to performance degradation in cluttered or occluded scenes. To address these issues, we propose an end-to-end reinforcement learning-based AVN framework with two key innovations: (1) a Stereo-Aware Attention Module (SAM), which learns and exploits the spatial disparity between left and right audio channels to enhance directional sound perception; and (2) an Audio-Guided Dynamic Fusion Module (AGDF), which dynamically adjusts the fusion ratio between visual and auditory features based on audio cues, thereby improving robustness to environmental changes. Extensive experiments are conducted on two realistic 3D scene datasets, Replica and Matterport3D, demonstrating that our method significantly outperforms existing approaches in terms of navigation success rate and path efficiency. Notably, our model achieves over 40\% improvement under audio-only conditions compared to the best-performing baselines. These results highlight the importance of explicitly modeling spatial cues from stereo channels and performing deep multi-modal fusion for robust and efficient audio-visual navigation. | URL: https://arxiv.org/pdf/2509.16924 ||| 7. T칤tulo Original: Quantum Abduction: A New Paradigm for Reasoning under Uncertainty | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Abductive reasoning - the search for plausible explanations - has long been central to human inquiry, from forensics to medicine and scientific discovery. Yet formal approaches in AI have largely reduced abduction to eliminative search: hypotheses are treated as mutually exclusive, evaluated against consistency constraints or probability updates, and pruned until a single ""best"" explanation remains. This reductionist framing overlooks the way human reasoners sustain multiple explanatory lines in suspension, navigate contradictions, and generate novel syntheses. This paper introduces quantum abduction, a non-classical paradigm that models hypotheses in superposition, allows them to interfere constructively or destructively, and collapses only when coherence with evidence is reached. Grounded in quantum cognition and implemented with modern NLP embeddings and generative AI, the framework supports dynamic synthesis rather than premature elimination. Case studies span historical mysteries (Ludwig II of Bavaria, the ""Monster of Florence""), literary demonstrations (""Murder on the Orient Express""), medical diagnosis, and scientific theory change. Across these domains, quantum abduction proves more faithful to the constructive and multifaceted nature of human reasoning, while offering a pathway toward expressive and transparent AI reasoning systems. | URL: https://arxiv.org/pdf/2509.16958 ||| 8. T칤tulo Original: KAHAN: Knowledge-Augmented Hierarchical Analysis and Narration for Financial Data Narration | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:We propose KAHAN, a knowledge-augmented hierarchical framework that systematically extracts insights from raw tabular data at entity, pairwise, group, and system levels. KAHAN uniquely leverages LLMs as domain experts to drive the analysis. On DataTales financial reporting benchmark, KAHAN outperforms existing approaches by over 20% on narrative quality (GPT-4o), maintains 98.2% factuality, and demonstrates practical utility in human evaluation. Our results reveal that knowledge quality drives model performance through distillation, hierarchical analysis benefits vary with market complexity, and the framework transfers effectively to healthcare domains. The data and code are available at this https URL. | URL: https://arxiv.org/pdf/2509.17037 ||| 9. T칤tulo Original: From domain-landmark graph learning to problem-landmark graph generation | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Landmarks have long played a pivotal role in automated planning, serving as crucial elements for improving the planning algorithms. The main limitation of classical landmark extraction methods is their sensitivity to specific planning tasks. This results in landmarks fully tailored to individual instances, thereby limiting their applicability across other instances of the same planning domain. We propose a novel approach that learns landmark relationships from multiple planning tasks of a planning domain. This leads to the creation of a probabilistic lifted ordering graph, as a structure that captures weighted abstractions of relationships between parameterized landmarks. Although these orderings are not 100\% true (they are probabilistic), they can still be very useful in planning. Next, given a new planning task for that domain, we instantiate the relationships from that graph to this particular instance. This instantiation operates in two phases. First, it generates two graphs: the former instantiating information from the initial state and the latter from the goal state. Second, it combines these two graphs into one unified graph by searching equivalences to extract landmark orderings. We evaluate the precision and recallof the information found by our approach over well-known planning domains. | URL: https://arxiv.org/pdf/2509.17062 ||| 10. T칤tulo Original: RALLM-POI: Retrieval-Augmented LLM for Zero-shot Next POI Recommendation with Geographical Reranking | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Next point-of-interest (POI) recommendation predicts a user's next destination from historical movements. Traditional models require intensive training, while LLMs offer flexible and generalizable zero-shot solutions but often generate generic or geographically irrelevant results due to missing trajectory and spatial context. To address these issues, we propose RALLM-POI, a framework that couples LLMs with retrieval-augmented generation and self-rectification. We first propose a Historical Trajectory Retriever (HTR) that retrieves relevant past trajectories to serve as contextual references, which are then reranked by a Geographical Distance Reranker (GDR) for prioritizing spatially relevant trajectories. Lastly, an Agentic LLM Rectifier (ALR) is designed to refine outputs through self-reflection. Without additional training, RALLM-POI achieves substantial accuracy gains across three real-world Foursquare datasets, outperforming both conventional and LLM-based baselines. Code is released at this https URL. | URL: https://arxiv.org/pdf/2509.17066"
"Resume los siguientes 10 papers cient칤ficos y devuelve la respuesta en formato JSON v치lido. Para cada paper traduce el t칤tulo al espa침ol y crea un objeto con los campos especificados. Usa emojis apropiados (游뱄 para IA, 游눹 para software, 游 para seguridad, 游빏 para investigaci칩n, etc.). IMPORTANTE: Responde 칔NICAMENTE con el JSON v치lido, sin texto adicional antes o despu칠s. Estructura JSON requerida: {""papers"": [{""titulo_espa침ol"": ""游댧 [emoji apropiado] T칤tulo traducido"", ""categoria"": ""[emoji 游늭] Categor칤a del paper"", ""resumen"": ""[emoji 游닇] Resumen en m치ximo 3 l칤neas"", ""puntos_clave"": ""[emoji 游꿢] Aspectos m치s importantes"", ""enlace"": ""[emoji 游댕] URL del paper""}, ...]} A continuaci칩n vienen los papers: 1. T칤tulo Original: Intention-aware Hierarchical Diffusion Model for Long-term Trajectory Anomaly Detection | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Long-term trajectory anomaly detection is a challenging problem due to the diversity and complex spatiotemporal dependencies in trajectory data. Existing trajectory anomaly detection methods fail to simultaneously consider both the high-level intentions of agents as well as the low-level details of the agent's navigation when analysing an agent's trajectories. This limits their ability to capture the full diversity of normal trajectories. In this paper, we propose an unsupervised trajectory anomaly detection method named Intention-aware Hierarchical Diffusion model (IHiD), which detects anomalies through both high-level intent evaluation and low-level sub-trajectory analysis. Our approach leverages Inverse Q Learning as the high-level model to assess whether a selected subgoal aligns with an agent's intention based on predicted Q-values. Meanwhile, a diffusion model serves as the low-level model to generate sub-trajectories conditioned on subgoal information, with anomaly detection based on reconstruction error. By integrating both models, IHiD effectively utilises subgoal transition knowledge and is designed to capture the diverse distribution of normal trajectories. Our experiments show that the proposed method IHiD achieves up to 30.2% improvement in anomaly detection performance in terms of F1 score over state-of-the-art baselines. | URL: https://arxiv.org/pdf/2509.17068 ||| 2. T칤tulo Original: Governing Automated Strategic Intelligence | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Military and economic strategic competitiveness between nation-states will increasingly be defined by the capability and cost of their frontier artificial intelligence models. Among the first areas of geopolitical advantage granted by such systems will be in automating military intelligence. Much discussion has been devoted to AI systems enabling new military modalities, such as lethal autonomous weapons, or making strategic decisions. However, the ability of a country of ""CIA analysts in a data-center"" to synthesize diverse data at scale, and its implications, have been underexplored. Multimodal foundation models appear on track to automate strategic analysis previously done by humans. They will be able to fuse today's abundant satellite imagery, phone-location traces, social media records, and written documents into a single queryable system. We conduct a preliminary uplift study to empirically evaluate these capabilities, then propose a taxonomy of the kinds of ground truth questions these systems will answer, present a high-level model of the determinants of this system's AI capabilities, and provide recommendations for nation-states to remain strategically competitive within the new paradigm of automated intelligence. | URL: https://arxiv.org/pdf/2509.17087 ||| 3. T칤tulo Original: MCTS-EP: Empowering Embodied Planning with Online Preference Optimization | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:This paper introduces MCTS-EP, an online learning framework that combines large language models (LLM) with Monte Carlo Tree Search (MCTS) for training embodied agents. MCTS-EP integrates three key components: MCTS-guided exploration for preference data collection, efficient multi-modal reasoning mechanism, and iterative training pipeline based on preference optimization. We theoretically prove that MCTS-EP achieves better performance bounds than conventional on-policy algorithms when the loss function is strongly convex, and demonstrate that it can be formulated as a search-enhanced variant of GAIL. MCTS-EP achieves state-of-the-art performace across serval benchmarks. In ALFWorld, it achieves 92% and 87% success rates for textual and visual tasks. In WebShop, it reaches an average reward of 0.81. MTCS-EP also reduces average interaction steps from from 18.7/19.5 to 10.2/9.9 steps in visual this http URL available at: this https URL | URL: https://arxiv.org/pdf/2509.17116 ||| 4. T칤tulo Original: ARE: Scaling Up Agent Environments and Evaluations | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:We introduce Meta Agents Research Environments (ARE), a research platform for scalable creation of environments, integration of synthetic or real applications, and execution of agentic orchestrations. ARE provides simple abstractions to build complex and diverse environments, each with their own rules, tools, content, and verifiers, helping to bridge the gap between model development and real-world deployment. We also propose Gaia2, a benchmark built in ARE and designed to measure general agent capabilities. Beyond search and execution, Gaia2 requires agents to handle ambiguities and noise, adapt to dynamic environments, collaborate with other agents, and operate under temporal constraints. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new failure modes that are invisible in static settings. Our experiments show that no system dominates across the intelligence spectrum: stronger reasoning often comes at the cost of efficiency, and budget scaling curves plateau, highlighting the need for new architectures and adaptive compute strategies. Perhaps more importantly, ARE abstractions enable continuous extension of Gaia2 to other environments, empowering the community to rapidly create new benchmarks tailored to their domains. In AI's second half, progress increasingly depends on defining meaningful tasks and robust evaluations to drive frontier capabilities forward. | URL: https://arxiv.org/pdf/2509.17158 ||| 5. T칤tulo Original: Shall We Play a Game? Language Models for Open-ended Wargames | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Wargames are multi-faceted, multi-player depictions of conflict in which participants' decisions influence future events. Wargames are often used to explore the strategic implications of decision-making. However, it also encompasses entertainment-oriented simulations, ranging from _Chess_ to tabletop role-playing games like _Dungeons & Dragons_ (D&D). On the more open-ended side of the spectrum of wargames, players use natural language to convey their moves, and adjudicators propose outcomes. Language Models (LMs) are increasingly being considered for how they can provide insights into real-world, consequential decisions. We conduct a scoping literature review of a curated selection of 100 recent works on AI in wargames, from which we construct an ontology of wargames in terms of the creativity afforded to either the players or adjudicators. Focusing on the space of wargames with the most open-endedness for players and adjudicators, we distill a set of considerations for when and how to use LMs in different application areas. We also present a set of safety considerations, best practices for deploying LMs in open-ended wargames, and conclude with a set of high-impact open research challenges. | URL: https://arxiv.org/pdf/2509.17192 ||| 6. T칤tulo Original: MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:The generation quality of large language models (LLMs) is often improved by utilizing inference-time sequence-level scaling methods (e.g., Chain-of-Thought). We introduce hyper-parallel scaling, a complementary framework that improves prediction quality at the token level. Hyper-parallel scaling computes and aggregates multiple output proposals for a single token from the model. We implement this concept in Mixture-of-Experts (MoE) models, which we refer to as Roster of Experts (RoE). RoE is a training-free inference algorithm that turns a single MoE into a dynamic ensemble of MoEs. RoE injects controlled stochasticity into the expert routing mechanism, enabling it to sample multiple diverse experts for each token and aggregate their outputs for a more accurate final this http URL overcome the computational cost, we introduce an efficient batching strategy and a specialized KV-caching mechanism that minimizes compute and memory overhead. For example, RoE enables a 7B MoE model to match the performance of a 10.5B MoE model while using 30% less compute for inference. These gains are achieved without any fine-tuning of model parameters. | URL: https://arxiv.org/pdf/2509.17238 ||| 7. T칤tulo Original: Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Systematic Literature Reviews (SLRs) are foundational to evidence-based research but remain labor-intensive and prone to inconsistency across disciplines. We present an LLM-based SLR evaluation copilot built on a Multi-Agent System (MAS) architecture to assist researchers in assessing the overall quality of the systematic literature reviews. The system automates protocol validation, methodological assessment, and topic relevance checks using a scholarly database. Unlike conventional single-agent methods, our design integrates a specialized agentic approach aligned with PRISMA guidelines to support more structured and interpretable evaluations. We conducted an initial study on five published SLRs from diverse domains, comparing system outputs to expert-annotated PRISMA scores, and observed 84% agreement. While early results are promising, this work represents a first step toward scalable and accurate NLP-driven systems for interdisciplinary workflows and reveals their capacity for rigorous, domain-agnostic knowledge aggregation to streamline the review process. | URL: https://arxiv.org/pdf/2509.17240 ||| 8. T칤tulo Original: Mind the Gap: Comparing Model- vs Agentic-Level Red Teaming with Action-Graph Observability on GPT-OSS-20B | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:As the industry increasingly adopts agentic AI systems, understanding their unique vulnerabilities becomes critical. Prior research suggests that security flaws at the model level do not fully capture the risks present in agentic deployments, where models interact with tools and external environments. This paper investigates this gap by conducting a comparative red teaming analysis of GPT-OSS-20B, a 20-billion parameter open-source model. Using our observability framework AgentSeer to deconstruct agentic systems into granular actions and components, we apply iterative red teaming attacks with harmful objectives from HarmBench at two distinct levels: the standalone model and the model operating within an agentic loop. Our evaluation reveals fundamental differences between model level and agentic level vulnerability profiles. Critically, we discover the existence of agentic-only vulnerabilities, attack vectors that emerge exclusively within agentic execution contexts while remaining inert against standalone models. Agentic level iterative attacks successfully compromise objectives that completely failed at the model level, with tool-calling contexts showing 24\% higher vulnerability than non-tool contexts. Conversely, certain model-specific exploits work exclusively at the model level and fail when transferred to agentic contexts, demonstrating that standalone model vulnerabilities do not always generalize to deployed systems. | URL: https://arxiv.org/pdf/2509.17259 ||| 9. T칤tulo Original: CogAtom: From Cognitive Atoms to Olympiad-level Mathematical Reasoning in Large Language Models | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Mathematical reasoning poses significant challenges for Large Language Models (LLMs) due to its demand for multi-step reasoning and abstract conceptual integration. While recent test-time scaling techniques rely heavily on high-quality, challenging problems, the scarcity of Olympiad-level math problems remains a bottleneck. We introduce CogAtom, a novel cognitive atom-based framework for synthesizing mathematically rigorous and cognitively diverse problems. Unlike prior approaches, CogAtom models problem construction as a process of selecting and recombining fundamental reasoning units, cognitive atoms, extracted from human-authored solutions. A diversity-promoting random walk algorithm enables exploration of the cognitive atom space, while a constraint-based recombination mechanism ensures logical soundness and structural validity. The combinatorial nature of the graph structure provides a near-infinite space of reasoning paths, and the walk algorithm systematically explores this space to achieve large-scale synthesis of high-quality problems; meanwhile, by controlling the number of cognitive atoms, we can precisely adjust problem difficulty, ensuring diversity, scalability, and controllability of the generated problems. Experimental results demonstrate that CogAtom outperforms existing methods in accuracy, reasoning depth, and diversity, generating problems that closely match the difficulty of AIME while exceeding it in structural variation. Our work offers a cognitively grounded pathway toward scalable, high-quality math problem this http URL code is publicly available at this https URL. | URL: https://arxiv.org/pdf/2509.17318 ||| 10. T칤tulo Original: LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Increasing complexity in software systems places a growing demand on reasoning tools that unlock vulnerabilities manifest in source code. Many current approaches focus on vulnerability analysis as a classifying task, oversimplifying the nuanced and context-dependent real-world scenarios. Even though current code large language models (LLMs) excel in code understanding, they often pay little attention to security-specific reasoning. We propose LLaVul, a multimodal LLM tailored to provide fine-grained reasoning about code through question-answering (QA). Our model is trained to integrate paired code and natural queries into a unified space, enhancing reasoning and context-dependent insights about code vulnerability. To evaluate our model performance, we construct a curated dataset of real-world vulnerabilities paired with security-focused questions and answers. Our model outperforms state-of-the-art general-purpose and code LLMs in the QA and detection tasks. We further explain decision-making by conducting qualitative analysis to highlight capabilities and limitations. By integrating code and QA, LLaVul enables more interpretable and security-focused code understanding. | URL: https://arxiv.org/pdf/2509.17337"
"Resume los siguientes 10 papers cient칤ficos y devuelve la respuesta en formato JSON v치lido. Para cada paper traduce el t칤tulo al espa침ol y crea un objeto con los campos especificados. Usa emojis apropiados (游뱄 para IA, 游눹 para software, 游 para seguridad, 游빏 para investigaci칩n, etc.). IMPORTANTE: Responde 칔NICAMENTE con el JSON v치lido, sin texto adicional antes o despu칠s. Estructura JSON requerida: {""papers"": [{""titulo_espa침ol"": ""游댧 [emoji apropiado] T칤tulo traducido"", ""categoria"": ""[emoji 游늭] Categor칤a del paper"", ""resumen"": ""[emoji 游닇] Resumen en m치ximo 3 l칤neas"", ""puntos_clave"": ""[emoji 游꿢] Aspectos m치s importantes"", ""enlace"": ""[emoji 游댕] URL del paper""}, ...]} A continuaci칩n vienen los papers: 1. T칤tulo Original: Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Automating radiology report generation poses a dual challenge: building clinically reliable systems and designing rigorous evaluation protocols. We introduce a multi-agent reinforcement learning framework that serves as both a benchmark and evaluation environment for multimodal clinical reasoning in the radiology ecosystem. The proposed framework integrates large language models (LLMs) and large vision models (LVMs) within a modular architecture composed of ten specialized agents responsible for image analysis, feature extraction, report generation, review, and evaluation. This design enables fine-grained assessment at both the agent level (e.g., detection and segmentation accuracy) and the consensus level (e.g., report quality and clinical relevance). We demonstrate an implementation using chatGPT-4o on public radiology datasets, where LLMs act as evaluators alongside medical radiologist feedback. By aligning evaluation protocols with the LLM development lifecycle, including pretraining, finetuning, alignment, and deployment, the proposed benchmark establishes a path toward trustworthy deviance-based radiology report generation. | URL: https://arxiv.org/pdf/2509.17353 ||| 2. T칤tulo Original: Multi-Scenario Highway Lane-Change Intention Prediction: A Physics-Informed AI Framework for Three-Class Classification | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Lane-change maneuvers are a leading cause of highway accidents, underscoring the need for accurate intention prediction to improve the safety and decision-making of autonomous driving systems. While prior studies using machine learning and deep learning methods (e.g., SVM, CNN, LSTM, Transformers) have shown promise, most approaches remain limited by binary classification, lack of scenario diversity, and degraded performance under longer prediction horizons. In this study, we propose a physics-informed AI framework that explicitly integrates vehicle kinematics, interaction feasibility, and traffic-safety metrics (e.g., distance headway, time headway, time-to-collision, closing gap time) into the learning process. lane-change prediction is formulated as a three-class problem that distinguishes left change, right change, and no change, and is evaluated across both straight highway segments (highD) and complex ramp scenarios (exiD). By integrating vehicle kinematics with interaction features, our machine learning models, particularly LightGBM, achieve state-of-the-art accuracy and strong generalization. Results show up to 99.8% accuracy and 93.6% macro F1 on highD, and 96.1% accuracy and 88.7% macro F1 on exiD at a 1-second horizon, outperforming a two-layer stacked LSTM baseline. These findings demonstrate the practical advantages of a physics-informed and feature-rich machine learning framework for real-time lane-change intention prediction in autonomous driving systems. | URL: https://arxiv.org/pdf/2509.17354 ||| 3. T칤tulo Original: Correlation or Causation: Analyzing the Causal Structures of LLM and LRM Reasoning Process | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:LLMs suffer from critical reasoning issues such as unfaithfulness, bias, and inconsistency, since they lack robust causal underpinnings and may rely on superficial correlations rather than genuine understanding. Successive LRMs have emerged as a promising alternative, leveraging advanced training techniques such as reinforcement learning (RL) and distillation to improve task accuracy. However, the impact of these training methods on causality remains largely unexplored. In this study, we conduct a systematic causal analysis on LLMs and LRMs, examining structural causal models (SCMs) of four key variables: problem instruction (Z), thinking process (T), reasoning steps (X), and answer (Y). Our findings reveal that RLVR-trained LRMs exhibit enhanced causal reasoning capabilities, aligning more closely with ideal causal structures, while LLMs and distilled LRMs fail to address causality-related deficiencies. Our further investigation indicates that RLVR reduces spurious correlations and strengthens genuine causal patterns, thereby mitigating unfaithfulness and bias. In addition, our inspection on the dynamics of the RLVR training process observes a high correlation between reduced spurious features and improved causal structures, where the causal relationships consistently improve in the training process. This study contributes to the understanding of causality in reasoning models, highlights the critical role of RLVR in enhancing causal reasoning, and provides insights for designing future AI systems with stronger causal foundations. We release our code and data at this https URL. | URL: https://arxiv.org/pdf/2509.17380 ||| 4. T칤tulo Original: Program Synthesis via Test-Time Transduction | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:We introduce transductive program synthesis, a new formulation of the program synthesis task that explicitly leverages test inputs during synthesis. While prior approaches to program synthesis--whether based on natural language descriptions or input-output examples--typically aim to generalize from training examples, they often struggle with robustness, especially in real-world settings where training examples are limited and test inputs involve various edge cases. To address this, we propose a novel framework that improves robustness by treating synthesis as an active learning over a finite hypothesis class defined by programs' outputs. We use an LLM to predict outputs for selected test inputs and eliminate inconsistent hypotheses, where the inputs are chosen via a greedy maximin algorithm to minimize the number of LLM queries required. We evaluate our approach on two real-world datasets: Playgol, a string transformation benchmark, and MBPP+, a Python code generation benchmark. We demonstrate that our method significantly improves program synthesis in both accuracy and efficiency. We release our code at this https URL. | URL: https://arxiv.org/pdf/2509.17393 ||| 5. T칤tulo Original: Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:A key feature differentiating artificial general intelligence (AGI) from traditional AI is that AGI can perform composite tasks that require a wide range of capabilities. Although embodied agents powered by multimodal large language models (MLLMs) offer rich perceptual and interactive capabilities, it remains largely unexplored whether they can solve composite tasks. In the current work, we designed a set of composite tasks inspired by common daily activities observed in early childhood development. Within a dynamic and simulated home environment, these tasks span three core domains: object understanding, spatial intelligence, and social activity. We evaluated 17 leading proprietary and open-source MLLMs on these tasks. The results consistently showed poor performance across all three domains, indicating a substantial gap between current capabilities and general intelligence requirements. Together, our tasks offer a preliminary framework for evaluating the general capabilities of embodied agents, marking an early but significant step toward the development of embodied MLLMs and their real-world deployment. | URL: https://arxiv.org/pdf/2509.17425 ||| 6. T칤tulo Original: SPICED: A Synaptic Homeostasis-Inspired Framework for Unsupervised Continual EEG Decoding | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Human brain achieves dynamic stability-plasticity balance through synaptic homeostasis. Inspired by this biological principle, we propose SPICED: a neuromorphic framework that integrates the synaptic homeostasis mechanism for unsupervised continual EEG decoding, particularly addressing practical scenarios where new individuals with inter-individual variability emerge continually. SPICED comprises a novel synaptic network that enables dynamic expansion during continual adaptation through three bio-inspired neural mechanisms: (1) critical memory reactivation; (2) synaptic consolidation and (3) synaptic renormalization. The interplay within synaptic homeostasis dynamically strengthens task-discriminative memory traces and weakens detrimental memories. By integrating these mechanisms with continual learning system, SPICED preferentially replays task-discriminative memory traces that exhibit strong associations with newly emerging individuals, thereby achieving robust adaptations. Meanwhile, SPICED effectively mitigates catastrophic forgetting by suppressing the replay prioritization of detrimental memories during long-term continual learning. Validated on three EEG datasets, SPICED show its effectiveness. | URL: https://arxiv.org/pdf/2509.17439 ||| 7. T칤tulo Original: AI Pangaea: Unifying Intelligence Islands for Adapting Myriad Tasks | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:The pursuit of artificial general intelligence continuously demands generalization in one model across myriad tasks, even those not seen before. However, current AI models are isolated from each other for being limited to specific tasks, now first defined as Intelligence Islands. To unify Intelligence Islands into one, we propose Pangaea, the first AI supercontinent akin to the geological Pangaea. Pangaea encodes any data into a unified format and accumulates universal knowledge through pre-training on 296 datasets across diverse modalities. Eventually, it demonstrates remarkable generalization across 45 general tasks and 15 scientific tasks encompassing a wide range of scientific subjects. By investigating Pangaea deeper, the scaling effect of modality is revealed, quantifying the universal knowledge accumulation across modalities as the cumulative distribution function of a geometric distribution. On the whole, Pangaea shows strong potential to handle myriad tasks, indicating a new direction toward artificial general intelligence. | URL: https://arxiv.org/pdf/2509.17460 ||| 8. T칤tulo Original: A Multimodal Conversational Assistant for the Characterization of Agricultural Plots from Geospatial Open Data | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:The increasing availability of open Earth Observation (EO) and agricultural datasets holds great potential for supporting sustainable land management. However, their high technical entry barrier limits accessibility for non-expert users. This study presents an open-source conversational assistant that integrates multimodal retrieval and large language models (LLMs) to enable natural language interaction with heterogeneous agricultural and geospatial data. The proposed architecture combines orthophotos, Sentinel-2 vegetation indices, and user-provided documents through retrieval-augmented generation (RAG), allowing the system to flexibly determine whether to rely on multimodal evidence, textual knowledge, or both in formulating an answer. To assess response quality, we adopt an LLM-as-a-judge methodology using Qwen3-32B in a zero-shot, unsupervised setting, applying direct scoring in a multi-dimensional quantitative evaluation framework. Preliminary results show that the system is capable of generating clear, relevant, and context-aware responses to agricultural queries, while remaining reproducible and scalable across geographic regions. The primary contributions of this work include an architecture for fusing multimodal EO and textual knowledge sources, a demonstration of lowering the barrier to access specialized agricultural information through natural language interaction, and an open and reproducible design. | URL: https://arxiv.org/pdf/2509.17544 ||| 9. T칤tulo Original: Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:As generative models are advancing in quality and quantity for creating synthetic content, deepfakes begin to cause online mistrust. Deepfake detectors are proposed to counter this effect, however, misuse of detectors claiming fake content as real or vice versa further fuels this misinformation problem. We present the first comprehensive uncertainty analysis of deepfake detectors, systematically investigating how generative artifacts influence prediction confidence. As reflected in detectors' responses, deepfake generators also contribute to this uncertainty as their generative residues vary, so we cross the uncertainty analysis of deepfake detectors and generators. Based on our observations, the uncertainty manifold holds enough consistent information to leverage uncertainty for deepfake source detection. Our approach leverages Bayesian Neural Networks and Monte Carlo dropout to quantify both aleatoric and epistemic uncertainties across diverse detector architectures. We evaluate uncertainty on two datasets with nine generators, with four blind and two biological detectors, compare different uncertainty methods, explore region- and pixel-based uncertainty, and conduct ablation studies. We conduct and analyze binary real/fake, multi-class real/fake, source detection, and leave-one-out experiments between the generator/detector combinations to share their generalization capability, model calibration, uncertainty, and robustness against adversarial attacks. We further introduce uncertainty maps that localize prediction confidence at the pixel level, revealing distinct patterns correlated with generator-specific artifacts. Our analysis provides critical insights for deploying reliable deepfake detection systems and establishes uncertainty quantification as a fundamental requirement for trustworthy synthetic media detection. | URL: https://arxiv.org/pdf/2509.17550 ||| 10. T칤tulo Original: MontePrep: Monte-Carlo-Driven Automatic Data Preparation without Target Data Instances | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:In commercial systems, a pervasive requirement for automatic data preparation (ADP) is to transfer relational data from disparate sources to targets with standardized schema specifications. Previous methods rely on labor-intensive supervision signals or target table data access permissions, limiting their usage in real-world scenarios. To tackle these challenges, we propose an effective end-to-end ADP framework MontePrep, which enables training-free pipeline synthesis with zero target-instance requirements. MontePrep is formulated as an open-source large language model (LLM) powered tree-structured search problem. It consists of three pivot components, i.e., a data preparation action sandbox (DPAS), a fundamental pipeline generator (FPG), and an execution-aware pipeline optimizer (EPO). We first introduce DPAS, a lightweight action sandbox, to navigate the search-based pipeline generation. The design of DPAS circumvents exploration of infeasible pipelines. Then, we present FPG to build executable DP pipelines incrementally, which explores the predefined action sandbox by the LLM-powered Monte Carlo Tree Search. Furthermore, we propose EPO, which invokes pipeline execution results from sources to targets to evaluate the reliability of the generated pipelines in FPG. In this way, unreasonable pipelines are eliminated, thus facilitating the search process from both efficiency and effectiveness perspectives. Extensive experimental results demonstrate the superiority of MontePrep with significant improvement against five state-of-the-art competitors. | URL: https://arxiv.org/pdf/2509.17553"
"Resume los siguientes 10 papers cient칤ficos y devuelve la respuesta en formato JSON v치lido. Para cada paper traduce el t칤tulo al espa침ol y crea un objeto con los campos especificados. Usa emojis apropiados (游뱄 para IA, 游눹 para software, 游 para seguridad, 游빏 para investigaci칩n, etc.). IMPORTANTE: Responde 칔NICAMENTE con el JSON v치lido, sin texto adicional antes o despu칠s. Estructura JSON requerida: {""papers"": [{""titulo_espa침ol"": ""游댧 [emoji apropiado] T칤tulo traducido"", ""categoria"": ""[emoji 游늭] Categor칤a del paper"", ""resumen"": ""[emoji 游닇] Resumen en m치ximo 3 l칤neas"", ""puntos_clave"": ""[emoji 游꿢] Aspectos m치s importantes"", ""enlace"": ""[emoji 游댕] URL del paper""}, ...]} A continuaci칩n vienen los papers: 1. T칤tulo Original: LIMI: Less is More for Agency | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:We define Agency as the emergent capacity of AI systems to function as autonomous agents actively discovering problems, formulating hypotheses, and executing solutions through self-directed engagement with environments and tools. This fundamental capability marks the dawn of the Age of AI Agency, driven by a critical industry shift: the urgent need for AI systems that don't just think, but work. While current AI excels at reasoning and generating responses, industries demand autonomous agents that can execute tasks, operate tools, and drive real-world outcomes. As agentic intelligence becomes the defining characteristic separating cognitive systems from productive workers, efficiently cultivating machine autonomy becomes paramount. Current approaches assume that more data yields better agency, following traditional scaling laws from language modeling. We fundamentally challenge this paradigm. LIMI (Less Is More for Intelligent Agency) demonstrates that agency follows radically different development principles. Through strategic focus on collaborative software development and scientific research workflows, we show that sophisticated agentic intelligence can emerge from minimal but strategically curated demonstrations of autonomous behavior. Using only 78 carefully designed training samples, LIMI achieves 73.5% on comprehensive agency benchmarks, dramatically outperforming state-of-the-art models: Kimi-K2-Instruct (24.1%), DeepSeek-V3.1 (11.9%), Qwen3-235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%). Most strikingly, LIMI demonstrates 53.7% improvement over models trained on 10,000 samples-achieving superior agentic intelligence with 128 times fewer samples. Our findings establish the Agency Efficiency Principle: machine autonomy emerges not from data abundance but from strategic curation of high-quality agentic demonstrations. | URL: https://arxiv.org/pdf/2509.17567 ||| 2. T칤tulo Original: Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:In this work, we address the task of table image to LaTeX code generation, with the goal of automating the reconstruction of high-quality, publication-ready tables from visual inputs. A central challenge of this task lies in accurately handling complex tables -- those with large sizes, deeply nested structures, and semantically rich or irregular cell content -- where existing methods often fail. We begin with a comprehensive analysis, identifying key challenges and highlighting the limitations of current evaluation protocols. To overcome these issues, we propose a reinforced multimodal large language model (MLLM) framework, where a pre-trained MLLM is fine-tuned on a large-scale table-to-LaTeX dataset. To further improve generation quality, we introduce a dual-reward reinforcement learning strategy based on Group Relative Policy Optimization (GRPO). Unlike standard approaches that optimize purely over text outputs, our method incorporates both a structure-level reward on LaTeX code and a visual fidelity reward computed from rendered outputs, enabling direct optimization of the visual output quality. We adopt a hybrid evaluation protocol combining TEDS-Structure and CW-SSIM, and show that our method achieves state-of-the-art performance, particularly on structurally complex tables, demonstrating the effectiveness and robustness of our approach. | URL: https://arxiv.org/pdf/2509.17589 ||| 3. T칤tulo Original: EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Large language models (LLMs) have shown strong performance on mathematical reasoning under well-posed conditions. However, real-world engineering problems require more than mathematical symbolic computation -- they need to deal with uncertainty, context, and open-ended scenarios. Existing benchmarks fail to capture these complexities. We introduce EngiBench, a hierarchical benchmark designed to evaluate LLMs on solving engineering problems. It spans three levels of increasing difficulty (foundational knowledge retrieval, multi-step contextual reasoning, and open-ended modeling) and covers diverse engineering subfields. To facilitate a deeper understanding of model performance, we systematically rewrite each problem into three controlled variants (perturbed, knowledge-enhanced, and math abstraction), enabling us to separately evaluate the model's robustness, domain-specific knowledge, and mathematical reasoning abilities. Experiment results reveal a clear performance gap across levels: models struggle more as tasks get harder, perform worse when problems are slightly changed, and fall far behind human experts on the high-level engineering tasks. These findings reveal that current LLMs still lack the high-level reasoning needed for real-world engineering, highlighting the need for future models with deeper and more reliable problem-solving capabilities. Our source code and data are available at this https URL. | URL: https://arxiv.org/pdf/2509.17677 ||| 4. T칤tulo Original: Virtual Arc Consistency for Linear Constraints inCost Function Networks | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:In Constraint Programming, solving discrete minimization problems with hard and soft constraints can be done either using (i) soft global constraints, (ii) a reformulation into a linear program, or (iii) a reformulation into local cost functions. Approach (i) benefits from a vast catalog of constraints. Each soft constraint propagator communicates with other soft constraints only through the variable domains, resulting in weak lower bounds. Conversely, the approach (ii) provides a global view with strong bounds, but the size of the reformulation can be problematic. We focus on approach (iii) in which soft arc consistency (SAC) algorithms produce bounds of intermediate quality. Recently, the introduction of linear constraints as local cost functions increases their modeling expressiveness. We adapt an existing SAC algorithm to handle linear constraints. We show that our algorithm significantly improves the lower bounds compared to the original algorithm on several benchmarks, reducing solving time in some cases. | URL: https://arxiv.org/pdf/2509.17706 ||| 5. T칤tulo Original: DA-Mamba: Dialogue-aware selective state-space model for multimodal engagement estimation | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Human engagement estimation in conversational scenarios is essential for applications such as adaptive tutoring, remote healthcare assessment, and socially aware human--computer interaction. Engagement is a dynamic, multimodal signal conveyed by facial expressions, speech, gestures, and behavioral cues over time. In this work we introduce DA-Mamba, a dialogue-aware multimodal architecture that replaces attention-heavy dialogue encoders with Mamba-based selective state-space processing to achieve linear time and memory complexity while retaining expressive cross-modal reasoning. We design a Mamba dialogue-aware selective state-space model composed of three core modules: a Dialogue-Aware Encoder, and two Mamba-based fusion mechanisms: Modality-Group Fusion and Partner-Group Fusion, these modules achieve expressive dialogue understanding. Extensive experiments on three standard benchmarks (NoXi, NoXi-Add, and MPIIGI) show that DA-Mamba surpasses prior state-of-the-art (SOTA) methods in concordance correlation coefficient (CCC), while reducing training time and peak memory; these gains enable processing much longer sequences and facilitate real-time deployment in resource-constrained, multi-party conversational settings. The source code will be available at: this https URL. | URL: https://arxiv.org/pdf/2509.17711 ||| 6. T칤tulo Original: Efficient & Correct Predictive Equivalence for Decision Trees | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:The Rashomon set of decision trees (DTs) finds importance uses. Recent work showed that DTs computing the same classification function, i.e. predictive equivalent DTs, can represent a significant fraction of the Rashomon set. Such redundancy is undesirable. For example, feature importance based on the Rashomon set becomes inaccurate due the existence of predictive equivalent DTs, i.e. DTs with the same prediction for every possible input. In recent work, McTavish et al. proposed solutions for several computational problems related with DTs, including that of deciding predictive equivalent DTs. This approach, which this paper refers to as MBDSR, consists of applying the well-known method of Quine-McCluskey (QM) for obtaining minimum-size DNF (disjunctive normal form) representations of DTs, which are then used for comparing DTs for predictive equivalence. Furthermore, the minimum-size DNF representation was also applied to computing explanations for the predictions made by DTs, and to finding predictions in the presence of missing data. However, the problem of formula minimization is hard for the second level of the polynomial hierarchy, and the QM method may exhibit worst-case exponential running time and space. This paper first demonstrates that there exist decision trees that trigger the worst-case exponential running time and space of the QM method. Second, the paper shows that the MBDSR approach can produce incorrect results for the problem of deciding predictive equivalence. Third, the paper shows that any of the problems to which the minimum-size DNF representation has been applied to can in fact be solved in polynomial time, in the size of the DT. The experiments confirm that, for DTs for which the the worst-case of the QM method is triggered, the algorithms proposed in this paper are orders of magnitude faster than the ones proposed by McTavish et al. | URL: https://arxiv.org/pdf/2509.17774 ||| 7. T칤tulo Original: Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Test-time scaling (TTS) has been shown to improve the performance of large language models (LLMs) by sampling and aggregating diverse reasoning paths. However, existing research has overlooked a critical issue: selection bias of reasoning strategies during scaling. Specifically, when generating reasoning processes, LLMs tend to follow certain strategies (e.g., algebraic solutions for math problems) while neglecting other valid alternatives (e.g., geometric solutions), resulting in insufficient exploration of the solution space. To further understand the impact of this bias, we present a theoretical analysis that reveals when it undermines the effectiveness of test-time scaling. Motivated by this theoretical insight, we introduce TTS-Uniform, a framework designed to mitigate the selection bias of reasoning strategies. It (i) identifies potential strategies, (ii) uniformly allocates the sampling budget across them, and (iii) filters out unstable strategies prior to aggregation. Experimental results show that TTS-Uniform significantly enhances scaling effectiveness across multiple mainstream LLMs and benchmark datasets. | URL: https://arxiv.org/pdf/2509.17905 ||| 8. T칤tulo Original: MEF: A Systematic Evaluation Framework for Text-to-Image Models | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Rapid advances in text-to-image (T2I) generation have raised higher requirements for evaluation methodologies. Existing benchmarks center on objective capabilities and dimensions, but lack an application-scenario perspective, limiting external validity. Moreover, current evaluations typically rely on either ELO for overall ranking or MOS for dimension-specific scoring, yet both methods have inherent shortcomings and limited interpretability. Therefore, we introduce the Magic Evaluation Framework (MEF), a systematic and practical approach for evaluating T2I models. First, we propose a structured taxonomy encompassing user scenarios, elements, element compositions, and text expression forms to construct the Magic-Bench-377, which supports label-level assessment and ensures a balanced coverage of both user scenarios and capabilities. On this basis, we combine ELO and dimension-specific MOS to generate model rankings and fine-grained assessments respectively. This joint evaluation method further enables us to quantitatively analyze the contribution of each dimension to user satisfaction using multivariate logistic regression. By applying MEF to current T2I models, we obtain a leaderboard and key characteristics of the leading models. We release our evaluation framework and make Magic-Bench-377 fully open-source to advance research in the evaluation of visual generative models. | URL: https://arxiv.org/pdf/2509.17907 ||| 9. T칤tulo Original: Orcust: Stepwise-Feedback Reinforcement Learning for GUI Agent | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Recent advances in GUI agents have achieved remarkable grounding and action-prediction performance, yet existing models struggle with unreliable reward signals and limited online trajectory generation. In this paper, we introduce Orcust, a framework that integrates Principle-Constrained Reward Modeling (PCRM) and Online VM-Grounded Trajectory Construction (OVTC) to enhance reasoning reliability and data efficiency in interactive GUI tasks. We leverages environment-verifiable and LLM-derived principle to enforce interpretable reward signals that constrain long chain-of-thought reasoning and rule-based feedback. OVTC spins up instrumented virtual machines to autonomously collect structured GUI interaction trajectories with explicit procedural and structural objectives, enabling the training of a stepwise reward model that robustly captures human preferences and adheres to task-specific constraints. Extensive experiments on standard GUI benchmarks covering perceptual grounding, foundational operations, and end-to-end task execution reveal that Orcust achieves state-of-the-art performance, improving by 22.2\% on ScreenSpot and 23.9\% on ScreenSpot-Pro over the base model (i.e. Qwen2.5-VL-7B). The results demonstrate Orcust's effectiveness in enhancing the reasoning, adaptability and scalability of GUI agents across various environments and task complexities. | URL: https://arxiv.org/pdf/2509.17917 ||| 10. T칤tulo Original: I think this is fair'': Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Assessing fairness in artificial intelligence (AI) typically involves AI experts who select protected features, fairness metrics, and set fairness thresholds. However, little is known about how stakeholders, particularly those affected by AI outcomes but lacking AI expertise, assess fairness. To address this gap, we conducted a qualitative study with 30 stakeholders without AI expertise, representing potential decision subjects in a credit rating scenario, to examine how they assess fairness when placed in the role of deciding on features with priority, metrics, and thresholds. We reveal that stakeholders' fairness decisions are more complex than typical AI expert practices: they considered features far beyond legally protected features, tailored metrics for specific contexts, set diverse yet stricter fairness thresholds, and even preferred designing customized fairness. Our results extend the understanding of how stakeholders can meaningfully contribute to AI fairness governance and mitigation, underscoring the importance of incorporating stakeholders' nuanced fairness judgments. | URL: https://arxiv.org/pdf/2509.17956"
"Resume los siguientes 10 papers cient칤ficos y devuelve la respuesta en formato JSON v치lido. Para cada paper traduce el t칤tulo al espa침ol y crea un objeto con los campos especificados. Usa emojis apropiados (游뱄 para IA, 游눹 para software, 游 para seguridad, 游빏 para investigaci칩n, etc.). IMPORTANTE: Responde 칔NICAMENTE con el JSON v치lido, sin texto adicional antes o despu칠s. Estructura JSON requerida: {""papers"": [{""titulo_espa침ol"": ""游댧 [emoji apropiado] T칤tulo traducido"", ""categoria"": ""[emoji 游늭] Categor칤a del paper"", ""resumen"": ""[emoji 游닇] Resumen en m치ximo 3 l칤neas"", ""puntos_clave"": ""[emoji 游꿢] Aspectos m치s importantes"", ""enlace"": ""[emoji 游댕] URL del paper""}, ...]} A continuaci칩n vienen los papers: 1. T칤tulo Original: On the Variational Costs of Changing Our Minds | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:The human mind is capable of extraordinary achievements, yet it often appears to work against itself. It actively defends its cherished beliefs even in the face of contradictory evidence, conveniently interprets information to conform to desired narratives, and selectively searches for or avoids information to suit its various purposes. Despite these behaviours deviating from common normative standards for belief updating, we argue that such 'biases' are not inherently cognitive flaws, but rather an adaptive response to the significant pragmatic and cognitive costs associated with revising one's beliefs. This paper introduces a formal framework that aims to model the influence of these costs on our belief updating mechanisms. We treat belief updating as a motivated variational decision, where agents weigh the perceived 'utility' of a belief against the informational cost required to adopt a new belief state, quantified by the Kullback-Leibler divergence from the prior to the variational posterior. We perform computational experiments to demonstrate that simple instantiations of this resource-rational model can be used to qualitatively emulate commonplace human behaviours, including confirmation bias and attitude polarisation. In doing so, we suggest that this framework makes steps toward a more holistic account of the motivated Bayesian mechanics of belief change and provides practical insights for predicting, compensating for, and correcting deviations from desired belief updating processes. | URL: https://arxiv.org/pdf/2509.17957 ||| 2. T칤tulo Original: The STAR-XAI Protocol: An Interactive Framework for Inducing Second-Order Agency in AI Agents | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Current Large Reasoning Models (LRMs) exhibit significant limitations in reliability and transparency, often showing a collapse in reasoning capabilities when faced with high-complexity, long-horizon tasks. This ""illusion of thinking"" is frequently an artifact of non-agentic, black-box evaluation paradigms that fail to cultivate robust problem-solving processes. In response, we introduce The STAR-XAI Protocol (Socratic, Transparent, Agentic, Reasoning - for eXplainable Artificial Intelligence), a novel methodology for training and operating verifiably reliable AI agents. Our method reframes the human-AI interaction as a structured, Socratic dialogue, governed by an explicit and evolving rulebook, the Consciousness Transfer Package (CTP). Through an interactive Gameplay Cycle that enforces ante-hoc strategic justification and a state-locking Checksum that prevents error accumulation, the protocol transforms a powerful but opaque LRM into a disciplined ""Clear Box"" agent. We demonstrate the efficacy of this method through an exhaustive 25-move case study in the complex strategic game ""Caps i Caps"". The agent not only solved the high-complexity puzzle but also demonstrated Second-Order Agency, identifying flaws in its own supervisor-approved plans and adapting its core integrity protocols mid-task. The STAR-XAI Protocol offers a practical pathway to creating AI agents that are not just high-performing, but also transparent, auditable, and trustworthy by design. | URL: https://arxiv.org/pdf/2509.17978 ||| 3. T칤tulo Original: Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:Large language models (LLMs) have demonstrated strong reasoning and tool-use capabilities, yet they often fail in real-world tool-interactions due to incorrect parameterization, poor tool selection, or misinterpretation of user intent. These issues often stem from an incomplete understanding of user goals and inadequate comprehension of tool documentation. While Chain-of-Thought (CoT) prompting has proven effective for enhancing reasoning in general contexts, our analysis reveals that free-form CoT is insufficient and sometimes counterproductive for structured function-calling tasks. To address this, we introduce a curriculum-inspired framework that leverages structured reasoning templates to guide LLMs through more deliberate step-by-step instructions for generating function callings. Experimental results show that our method reduces tool-use errors, achieving 3-12% relative improvements over strong baselines across diverse model series and approaches. Moreover, our framework enhances the robustness, interpretability, and transparency of tool-using agents, advancing the development of more reliable AI assistants for real-world applications. | URL: https://arxiv.org/pdf/2509.18076 ||| 4. T칤tulo Original: Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning | Categor칤a: Artificial Intelligence | Descripci칩n: Abstract:We introduce Reasoning Core, a new scalable environment for Reinforcement Learning with Verifiable Rewards (RLVR), designed to advance foundational symbolic reasoning in Large Language Models (LLMs). Unlike existing benchmarks that focus on games or isolated puzzles, Reasoning Core procedurally generates problems across core formal domains, including PDDL planning, first-order logic, context-free grammar parsing, causal reasoning, and system equation solving. The environment is built on key design principles of high-generality problem distributions, verification via external tools, and continuous difficulty control, which together provide a virtually infinite supply of novel training instances. Initial zero-shot evaluations with frontier LLMs confirm the difficulty of Reasoning Core's tasks, positioning it as a promising resource to improve the reasoning capabilities of future models. | URL: https://arxiv.org/pdf/2509.18083 ||| 5. T칤tulo Original: Digging Into the Internal: Causality-Based Analysis of LLM Function Calling | Categor칤a: Software Engineering | Descripci칩n: Abstract:Function calling (FC) has emerged as a powerful technique for facilitating large language models (LLMs) to interact with external systems and perform structured tasks. However, the mechanisms through which it influences model behavior remain largely under-explored. Besides, we discover that in addition to the regular usage of FC, this technique can substantially enhance the compliance of LLMs with user instructions. These observations motivate us to leverage causality, a canonical analysis method, to investigate how FC works within LLMs. In particular, we conduct layer-level and token-level causal interventions to dissect FC's impact on the model's internal computational logic when responding to user queries. Our analysis confirms the substantial influence of FC and reveals several in-depth insights into its mechanisms. To further validate our findings, we conduct extensive experiments comparing the effectiveness of FC-based instructions against conventional prompting methods. We focus on enhancing LLM safety robustness, a critical LLM application scenario, and evaluate four mainstream LLMs across two benchmark datasets. The results are striking: FC shows an average performance improvement of around 135% over conventional prompting methods in detecting malicious inputs, demonstrating its promising potential to enhance LLM reliability and capability in practical applications. | URL: https://arxiv.org/pdf/2509.16268 ||| 6. T칤tulo Original: Constrained Co-evolutionary Metamorphic Differential Testing for Autonomous Systems with an Interpretability Approach | Categor칤a: Software Engineering | Descripci칩n: Abstract:Autonomous systems, such as autonomous driving systems, evolve rapidly through frequent updates, risking unintended behavioral degradations. Effective system-level testing is challenging due to the vast scenario space, the absence of reliable test oracles, and the need for practically applicable and interpretable test cases. We present CoCoMagic, a novel automated test case generation method that combines metamorphic testing, differential testing, and advanced search-based techniques to identify behavioral divergences between versions of autonomous systems. CoCoMagic formulates test generation as a constrained cooperative co-evolutionary search, evolving both source scenarios and metamorphic perturbations to maximize differences in violations of predefined metamorphic relations across versions. Constraints and population initialization strategies guide the search toward realistic, relevant scenarios. An integrated interpretability approach aids in diagnosing the root causes of divergences. We evaluate CoCoMagic on an end-to-end ADS, InterFuser, within the Carla virtual simulator. Results show significant improvements over baseline search methods, identifying up to 287\% more distinct high-severity behavioral differences while maintaining scenario realism. The interpretability approach provides actionable insights for developers, supporting targeted debugging and safety assessment. CoCoMagic offers an efficient, effective, and interpretable way for the differential testing of evolving autonomous systems across versions. | URL: https://arxiv.org/pdf/2509.16478 ||| 7. T칤tulo Original: Causal Fuzzing for Verifying Machine Unlearning | Categor칤a: Software Engineering | Descripci칩n: Abstract:As machine learning models become increasingly embedded in decision-making systems, the ability to ""unlearn"" targeted data or features is crucial for enhancing model adaptability, fairness, and privacy in models which involves expensive training. To effectively guide machine unlearning, a thorough testing is essential. Existing methods for verification of machine unlearning provide limited insights, often failing in scenarios where the influence is indirect. In this work, we propose CAF칄, a new causality based framework that unifies datapoint- and feature-level unlearning for verification of black-box ML models. CAF칄 evaluates both direct and indirect effects of unlearning targets through causal dependencies, providing actionable insights with fine-grained analysis. Our evaluation across five datasets and three model architectures demonstrates that CAF칄 successfully detects residual influence missed by baselines while maintaining computational efficiency. | URL: https://arxiv.org/pdf/2509.16525 ||| 8. T칤tulo Original: Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing | Categor칤a: Software Engineering | Descripci칩n: Abstract:As quantum computing continues to emerge, ensuring the quality of quantum programs has become increasingly critical. Quantum program testing has emerged as a prominent research area within the scope of quantum software engineering. While numerous approaches have been proposed to address quantum program quality assurance, our analysis reveals that most existing methods rely on measurement-based validation in practice. However, due to the inherently probabilistic nature of quantum programs, measurement-based validation methods face significant limitations. To investigate these limitations, we conducted an empirical study of recent research on quantum program testing, analyzing measurement-based validation methods in the literature. Our analysis categorizes existing measurement-based validation methods into two groups: distribution-level validation and output-value-level validation. We then compare measurement-based validation with statevector-based validation methods to evaluate their pros and cons. Our findings demonstrate that measurement-based validation is suitable for straightforward assessments, such as verifying the existence of specific output values, while statevector-based validation proves more effective for complicated tasks such as assessing the program behaviors. | URL: https://arxiv.org/pdf/2509.16595 ||| 9. T칤tulo Original: Incentives and Outcomes in Bug Bounties | Categor칤a: Software Engineering | Descripci칩n: Abstract:Bug bounty programs have contributed significantly to security in technology firms in the last decade, but little is known about the role of reward incentives in producing useful outcomes. We analyze incentives and outcomes in Google's Vulnerability Rewards Program (VRP), one of the world's largest bug bounty programs. We analyze the responsiveness of the quality and quantity of bugs received to changes in payments, focusing on a change in Google's reward amounts posted in July, 2024, in which reward amounts increased by up to 200% for the highest impact tier. Our empirical results show an increase in the volume of high-value bugs received after the reward increase, for which we also compute elasticities. We further break down the sources of this increase between veteran researchers and new researchers, showing that the reward increase both redirected the attention of veteran researchers and attracted new top security researchers into the program. | URL: https://arxiv.org/pdf/2509.16655 ||| 10. T칤tulo Original: Verifying User Interfaces using SPARK Ada: A Case Study of the T34 Syringe Driver | Categor칤a: Software Engineering | Descripci칩n: Abstract:The increase in safety and critical systems improved Healthcare. Due to their risk of harm, such systems are subject to stringent guidelines and compliances. These safety measures ensure a seamless experience and mitigate the risk to end-users. Institutions like the Food and Drug Administration and the NHS, respectively, established international standards and competency frameworks to ensure industry compliance with these safety concerns. Medical device manufacturing is mainly concerned with standards. Consequently, these standards now advocate for better human factors considered in user interaction for medical devices. This forces manufacturers to rely on heavy testing and review to cover many of these factors during development. Sadly, many human factor risks will not be caught until proper testing in real life, which might be catastrophic in the case of an ambulatory device like the T34 syringe pump. Therefore, effort in formal methods research may propose new solutions in anticipating these errors in the early stages of development or even reducing their occurrence based on the use of standard generic model. These generically developed models will provide a common framework for safety integration in industry and may potentially be proven using formal verification mathematical proofs. This research uses SPARK Ada's formal verification tool against a behavioural model of the T34 syringe driver. A Generic Infusion Pump model refinement is explored and implemented in SPARK Ada. As a subset of the Ada language, the verification level of the end prototype is evaluated using SPARK. Exploring potential limitations defines the proposed model's implementation liability when considering abstraction and components of User Interface design in SPARK Ada. | URL: https://arxiv.org/pdf/2509.16681"
"Resume los siguientes 10 papers cient칤ficos y devuelve la respuesta en formato JSON v치lido. Para cada paper traduce el t칤tulo al espa침ol y crea un objeto con los campos especificados. Usa emojis apropiados (游뱄 para IA, 游눹 para software, 游 para seguridad, 游빏 para investigaci칩n, etc.). IMPORTANTE: Responde 칔NICAMENTE con el JSON v치lido, sin texto adicional antes o despu칠s. Estructura JSON requerida: {""papers"": [{""titulo_espa침ol"": ""游댧 [emoji apropiado] T칤tulo traducido"", ""categoria"": ""[emoji 游늭] Categor칤a del paper"", ""resumen"": ""[emoji 游닇] Resumen en m치ximo 3 l칤neas"", ""puntos_clave"": ""[emoji 游꿢] Aspectos m치s importantes"", ""enlace"": ""[emoji 游댕] URL del paper""}, ...]} A continuaci칩n vienen los papers: 1. T칤tulo Original: RelRepair: Enhancing Automated Program Repair by Retrieving Relevant Code | Categor칤a: Software Engineering | Descripci칩n: Abstract:Automated Program Repair (APR) has emerged as a promising paradigm for reducing debugging time and improving the overall efficiency of software development. Recent advances in Large Language Models (LLMs) have demonstrated their potential for automated bug fixing and other software engineering tasks. Nevertheless, the general-purpose nature of LLM pre-training means these models often lack the capacity to perform project-specific repairs, which require understanding of domain-specific identifiers, code structures, and contextual relationships within a particular codebase. As a result, LLMs may struggle to generate correct patches when the repair depends on project-specific information. To address this limitation, we introduce RelRepair, a novel approach that retrieves relevant project-specific code to enhance automated program repair. RelRepair first identifies relevant function signatures by analyzing function names and code comments within the project. It then conducts deeper code analysis to retrieve code snippets relevant to the repair context. The retrieved relevant information is then incorporated into the LLM's input prompt, guiding the model to generate more accurate and informed patches. We evaluate RelRepair on two widely studied datasets, Defects4J V1.2 and ManySStuBs4J, and compare its performance against several state-of-the-art LLM-based APR approaches. RelRepair successfully repairs 101 bugs in Defects4J V1.2. Furthermore, RelRepair achieves a 17.1\% improvement in the ManySStuBs4J dataset, increasing the overall fix rate to 48.3\%. These results highlight the importance of providing relevant project-specific information to LLMs, shedding light on effective strategies for leveraging LLMs in APR tasks. | URL: https://arxiv.org/pdf/2509.16701 ||| 2. T칤tulo Original: Can We Trust the AI Pair Programmer? Copilot for API Misuse Detection and Correction | Categor칤a: Software Engineering | Descripci칩n: Abstract:API misuse introduces security vulnerabilities, system failures, and increases maintenance costs, all of which remain critical challenges in software development. Existing detection approaches rely on static analysis or machine learning-based tools that operate post-development, which delays defect resolution. Delayed defect resolution can significantly increase the cost and complexity of maintenance and negatively impact software reliability and user trust. AI-powered code assistants, such as GitHub Copilot, offer the potential for real-time API misuse detection within development environments. This study evaluates GitHub Copilot's effectiveness in identifying and correcting API misuse using MUBench, which provides a curated benchmark of misuse cases. We construct 740 misuse examples, manually and via AI-assisted variants, using correct usage patterns and misuse specifications. These examples and 147 correct usage cases are analyzed using Copilot integrated in Visual Studio Code. Copilot achieved a detection accuracy of 86.2%, precision of 91.2%, and recall of 92.4%. It performed strongly on common misuse types (e.g., missing-call, null-check) but struggled with compound or context-sensitive cases. Notably, Copilot successfully fixed over 95% of the misuses it identified. These findings highlight both the strengths and limitations of AI-driven coding assistants, positioning Copilot as a promising tool for real-time pair programming and detecting and fixing API misuses during software development. | URL: https://arxiv.org/pdf/2509.16795 ||| 3. T칤tulo Original: Implementation of the Collision Avoidance System for DO-178C Compliance | Categor칤a: Software Engineering | Descripci칩n: Abstract:This technical report presents the detailed implementation of a Collision Avoidance System (CAS) for Unmanned Aerial Vehicles (UAVs), developed as a case study to demonstrate a rigorous methodology for achieving DO-178C compliance in safety-critical software. The CAS is based on functional requirements inspired by NASA's Access 5 project and is designed to autonomously detect, evaluate, and avoid potential collision threats in real-time, supporting the safe integration of UAVs into civil airspace. The implementation environment combines formal methods, model-based development, and automated verification tools, including Alloy, SPIN, Simulink Embedded Coder, and the LDRA tool suite. The report documents each phase of the software lifecycle: requirements specification and validation, architectural and detailed design, coding, verification, and traceability, with a strong focus on compliance with DO-178C Design Assurance Level B objectives. Results demonstrate that formal modelling and automated toolchains enabled early detection and correction of specification defects, robust traceability, and strong evidence of verification and validation across all development stages. Static and dynamic analyses confirmed code quality and coverage, while formal verification methods provided mathematical assurance of correctness for critical components. Although the integration phase was not fully implemented, the approach proved effective in addressing certification challenges for UAV safety-critical systems. \keywords Collision Avoidance System (CAS), Unmanned Aerial Vehicles (UAVs), DO-178C compliance, Safety-critical software, Formal methods, Model-based development, Alloy, SPIN model checker, Simulink Embedded Coder, LDRA tool suite, Software verification and validation, Traceability, Certification. | URL: https://arxiv.org/pdf/2509.16844 ||| 4. T칤tulo Original: MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions | Categor칤a: Software Engineering | Descripci칩n: Abstract:Mobile operating systems (OS) are frequently updated, but such updates can unintentionally degrade user experience by introducing performance regressions. Existing detection techniques often rely on system-level metrics (e.g., CPU or memory usage) or focus on specific OS components, which may miss regressions actually perceived by users -- such as slower responses or UI stutters. To address this gap, we present MobileUPReg, a black-box framework for detecting user-perceived performance regressions across OS versions. MobileUPReg runs the same apps under different OS versions and compares user-perceived performance metrics -- response time, finish time, launch time, and dropped frames -- to identify regressions that are truly perceptible to users. In a large-scale study, MobileUPReg achieves high accuracy in extracting user-perceived metrics and detects user-perceived regressions with 0.96 precision, 0.91 recall, and 0.93 F1-score -- significantly outperforming a statistical baseline using the Wilcoxon rank-sum test and Cliff's Delta. MobileUPReg has been deployed in an industrial CI pipeline, where it analyzes thousands of screencasts across hundreds of apps daily and has uncovered regressions missed by traditional tools. These results demonstrate that MobileUPReg enables accurate, scalable, and perceptually aligned regression detection for mobile OS validation. | URL: https://arxiv.org/pdf/2509.16864 ||| 5. T칤tulo Original: DecipherGuard: Understanding and Deciphering Jailbreak Prompts for a Safer Deployment of Intelligent Software Systems | Categor칤a: Software Engineering | Descripci칩n: Abstract:Intelligent software systems powered by Large Language Models (LLMs) are increasingly deployed in critical sectors, raising concerns about their safety during runtime. Through an industry-academic collaboration when deploying an LLM-powered virtual customer assistant, a critical software engineering challenge emerged: how to enhance a safer deployment of LLM-powered software systems at runtime? While LlamaGuard, the current state-of-the-art runtime guardrail, offers protection against unsafe inputs, our study reveals a Defense Success Rate (DSR) drop of 24% under obfuscation- and template-based jailbreak attacks. In this paper, we propose DecipherGuard, a novel framework that integrates a deciphering layer to counter obfuscation-based prompts and a low-rank adaptation mechanism to enhance guardrail effectiveness against template-based attacks. Empirical evaluation on over 22,000 prompts demonstrates that DecipherGuard improves DSR by 36% to 65% and Overall Guardrail Performance (OGP) by 20% to 50% compared to LlamaGuard and two other runtime guardrails. These results highlight the effectiveness of DecipherGuard in defending LLM-powered software systems against jailbreak attacks during runtime. | URL: https://arxiv.org/pdf/2509.16870 ||| 6. T칤tulo Original: Deep Synthetic Cross-Project Approaches for Software Reliability Growth Modeling | Categor칤a: Software Engineering | Descripci칩n: Abstract:Software Reliability Growth Models (SRGMs) are widely used to predict software reliability based on defect discovery data collected during testing or operational phases. However, their predictive accuracy often degrades in data-scarce environments, such as early-stage testing or safety-critical systems. Although cross-project transfer learning has been explored to mitigate this issue by leveraging data from past projects, its applicability remains limited due to the scarcity and confidentiality of real-world datasets. To overcome these limitations, we propose Deep Synthetic Cross-project SRGM (DSC-SRGM), a novel approach that integrates synthetic data generation with cross-project transfer learning. Synthetic datasets are generated using traditional SRGMs to preserve the statistical characteristics of real-world defect discovery trends. A cross-correlation-based clustering method is applied to identify synthetic datasets with patterns similar to the target project. These datasets are then used to train a deep learning model for reliability prediction. The proposed method is evaluated on 60 real-world datasets, and its performance is compared with both traditional SRGMs and cross-project deep learning models trained on real-world datasets. DSC-SRGM achieves up to 23.3% improvement in predictive accuracy over traditional SRGMs and 32.2% over cross-project deep learning models trained on real-world datasets. However, excessive use of synthetic data or a naive combination of synthetic and real-world data may degrade prediction performance, highlighting the importance of maintaining an appropriate data balance. These findings indicate that DSC-SRGM is a promising approach for software reliability prediction in data-scarce environments. | URL: https://arxiv.org/pdf/2509.16939 ||| 7. T칤tulo Original: SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks? | Categor칤a: Software Engineering | Descripci칩n: Abstract:We introduce SWE-Bench Pro, a substantially more challenging benchmark that builds upon the best practices of SWE-BENCH [25], but is explicitly designed to capture realistic, complex, enterprise-level problems beyond the scope of SWE-BENCH. SWE-BENCH PRO contains 1,865 problems sourced from a diverse set of 41 actively maintained repositories spanning business applications, B2B services, and developer tools. The benchmark is partitioned into a public set with open access to problems sourced from 11 repositories, a held-out set of 12 repositories and a commercial set of 18 proprietary repositories where we have formal partnership agreements with early-stage startups. Problems in the held-out and the commercial set are not publicly accessible, but we release results on the commercial set. Our benchmark features long-horizon tasks that may require hours to days for a professional software engineer to complete, often involving patches across multiple files and substantial code modifications. All tasks are human-verified and augmented with sufficient context to ensure resolvability. In our evaluation of widely used coding models, under a unified scaffold, we observe that their performance on SWE-Bench PRO remains below 25% (Pass@1), with GPT-5 achieving the highest score to date at 23.3%. To better understand these limitations, we cluster the failure modes observed in the collected agent trajectories for a clearer characterization of the error patterns exhibited by current models. Overall, SWE-BENCH PRO provides a contamination-resistant testbed that more faithfully captures the complexity and diversity of real-world software development, advancing the pursuit of truly autonomous software engineering agents at a professional level. | URL: https://arxiv.org/pdf/2509.16941 ||| 8. T칤tulo Original: Static Security Vulnerability Scanning of Proprietary and Open-Source Software: An Adaptable Process with Variants and Results | Categor칤a: Software Engineering | Descripci칩n: Abstract:Software vulnerabilities remain a significant risk factor in achieving security objectives within software development organizations. This is especially true where either proprietary or open-source software (OSS) is included in the technological environment. In this paper an end-to-end process with supporting methods and tools is presented. This industry proven generic process allows for the custom instantiation, configuration, and execution of routinized code scanning for software vulnerabilities and their prioritized remediation. A select set of tools are described for this key DevSecOps function and placed into an iterative process. Examples of both industrial proprietary applications and open-source applications are provided including specific vulnerability instances and a discussion of their treatment. The benefits of each selected tool are considered, and alternative tools are also introduced. Application of this method in a comprehensive SDLC model is also reviewed along with prospective enhancements from automation and the application of advanced technologies including AI. Adoption of this method can be achieved with minimal adjustments and with maximum flexibility for results in reducing source code vulnerabilities, reducing supply chain risk, and improving the security profile of new or legacy solutions. | URL: https://arxiv.org/pdf/2509.16985 ||| 9. T칤tulo Original: Prompt-with-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering | Categor칤a: Software Engineering | Descripci칩n: Abstract:Large Language Models are transforming software engineering, yet prompt management in practice remains ad hoc, hindering reliability, reuse, and integration into industrial workflows. We present Prompt-with-Me, a practical solution for structured prompt management embedded directly in the development environment. The system automatically classifies prompts using a four-dimensional taxonomy encompassing intent, author role, software development lifecycle stage, and prompt type. To enhance prompt reuse and quality, Prompt-with-Me suggests language refinements, masks sensitive information, and extracts reusable templates from a developer's prompt library. Our taxonomy study of 1108 real-world prompts demonstrates that modern LLMs can accurately classify software engineering prompts. Furthermore, our user study with 11 participants shows strong developer acceptance, with high usability (Mean SUS=73), low cognitive load (Mean NASA-TLX=21), and reported gains in prompt quality and efficiency through reduced repetitive effort. Lastly, we offer actionable insights for building the next generation of prompt management and maintenance tools for software engineering workflows. | URL: https://arxiv.org/pdf/2509.17096 ||| 10. T칤tulo Original: Clotho: Measuring Task-Specific Pre-Generation Test Adequacy for LLM Inputs | Categor칤a: Software Engineering | Descripci칩n: Abstract:Software increasingly relies on the emergent capabilities of Large Language Models (LLMs), from natural language understanding to program analysis and generation. Yet testing them on specific tasks remains difficult and costly: many prompts lack ground truth, forcing reliance on human judgment, while existing uncertainty and adequacy measures typically require full inference. A key challenge is to assess input adequacy in a way that reflects the demands of the task, ideally before even generating any output. We introduce CLOTHO, a task-specific, pre-generation adequacy measure that estimates input difficulty directly from hidden LLM states. Given a large pool of unlabelled inputs for a specific task, CLOTHO uses a Gaussian Mixture Model (GMM) to adaptively sample the most informative cases for human labelling. Based on this reference set the GMM can then rank unseen inputs by their likelihood of failure. In our empirical evaluation across eight benchmark tasks and three open-weight LLMs, CLOTHO can predict failures with a ROC-AUC of 0.716, after labelling reference sets that are on average only 5.4% of inputs. It does so without generating any outputs, thereby reducing costs compared to existing uncertainty measures. Comparison of CLOTHO and post-generation uncertainty measures shows that the two approaches complement each other. Crucially, we show that adequacy scores learnt from open-weight LLMs transfer effectively to proprietary models, extending the applicability of the approach. When prioritising test inputs for proprietary models, CLOTHO increases the average number of failing inputs from 18.7 to 42.5 out of 100, compared to random prioritisation. | URL: https://arxiv.org/pdf/2509.17314"
"Resume los siguientes 10 papers cient칤ficos y devuelve la respuesta en formato JSON v치lido. Para cada paper traduce el t칤tulo al espa침ol y crea un objeto con los campos especificados. Usa emojis apropiados (游뱄 para IA, 游눹 para software, 游 para seguridad, 游빏 para investigaci칩n, etc.). IMPORTANTE: Responde 칔NICAMENTE con el JSON v치lido, sin texto adicional antes o despu칠s. Estructura JSON requerida: {""papers"": [{""titulo_espa침ol"": ""游댧 [emoji apropiado] T칤tulo traducido"", ""categoria"": ""[emoji 游늭] Categor칤a del paper"", ""resumen"": ""[emoji 游닇] Resumen en m치ximo 3 l칤neas"", ""puntos_clave"": ""[emoji 游꿢] Aspectos m치s importantes"", ""enlace"": ""[emoji 游댕] URL del paper""}, ...]} A continuaci칩n vienen los papers: 1. T칤tulo Original: BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing | Categor칤a: Software Engineering | Descripci칩n: Abstract:Fuzzing has shown great success in evaluating the robustness of intelligent natural language processing (NLP) software. As large language model (LLM)-based NLP software is widely deployed in critical industries, existing methods still face two main challenges: 1 testing methods are insufficiently coupled with the behavioral patterns of LLM-based NLP software; 2 fuzzing capability for the testing scenario of natural language generation (NLG) generally degrades. To address these issues, we propose BASFuzz, an efficient Fuzz testing method tailored for LLM-based NLP software. BASFuzz targets complete test inputs composed of prompts and examples, and uses a text consistency metric to guide mutations of the fuzzing loop, aligning with the behavioral patterns of LLM-based NLP software. A Beam-Annealing Search algorithm, which integrates beam search and simulated annealing, is employed to design an efficient fuzzing loop. In addition, information entropy-based adaptive adjustment and an elitism strategy further enhance fuzzing capability. We evaluate BASFuzz on six datasets in representative scenarios of NLG and natural language understanding (NLU). Experimental results demonstrate that BASFuzz achieves a testing effectiveness of 90.335% while reducing the average time overhead by 2,163.852 seconds compared to the current best baseline, enabling more effective robustness evaluation prior to software deployment. | URL: https://arxiv.org/pdf/2509.17335 ||| 2. T칤tulo Original: SLICET5: Static Program Slicing using Language Models with Copy Mechanism and Constrained Decoding | Categor칤a: Software Engineering | Descripci칩n: Abstract:Static program slicing is a fundamental technique in software engineering. Traditional static slicing tools rely on parsing complete source code, which limits their applicability to real-world scenarios where code snippets are incomplete or unparsable. While recent research developed learning-based approaches to predict slices, they face critical challenges: (1) Inaccurate dependency identification, where models fail to precisely capture data and control dependencies between code elements; and (2) Unconstrained generation, where models produce slices with extraneous or hallucinated tokens not present in the input, violating the structural integrity of slices. To address these challenges, we propose \ourtool, a novel slicing framework that reformulates static program slicing as a sequence-to-sequence task using lightweight language models (e.g., CodeT5+). Our approach incorporates two key innovations. First, we introduce a copy mechanism that enables the model to more accurately capture inter-element dependencies and directly copy relevant tokens from the input, improving both dependency reasoning and generation constraint. Second, we design a constrained decoding process with (a) lexical constraint, restricting outputs to input tokens only, and (b) syntactic constraint, leveraging Tree Similarity of Edit Distance (TSED) monotonicity to detect structurally invalid outputs and discard them. We evaluate \ourtool on CodeNet and LeetCode datasets and show it consistently outperforms state-of-the-art baselines, improving ExactMatch scores by up to 27\%. Furthermore, \ourtool demonstrates strong performance on incomplete code, highlighting its robustness and practical utility in real-world development environments. | URL: https://arxiv.org/pdf/2509.17338 ||| 3. T칤tulo Original: Prompts as Software Engineering Artifacts: A Research Agenda and Preliminary Findings | Categor칤a: Software Engineering | Descripci칩n: Abstract:Developers now routinely interact with large language models (LLMs) to support a range of software engineering (SE) tasks. This prominent role positions prompts as potential SE artifacts that, like other artifacts, may require systematic development, documentation, and maintenance. However, little is known about how prompts are actually used and managed in LLM-integrated workflows, what challenges practitioners face, and whether the benefits of systematic prompt management outweigh the associated effort. To address this gap, we propose a research programme that (a) characterizes current prompt practices, challenges, and influencing factors in SE; (b) analyzes prompts as software artifacts, examining their evolution, traceability, reuse, and the trade-offs of systematic management; and (c) develops and empirically evaluates evidence-based guidelines for managing prompts in LLM-integrated workflows. As a first step, we conducted an exploratory survey with 74 software professionals from six countries to investigate current prompt practices and challenges. The findings reveal that prompt usage in SE is largely ad-hoc: prompts are often refined through trial-and-error, rarely reused, and shaped more by individual heuristics than standardized practices. These insights not only highlight the need for more systematic approaches to prompt management but also provide the empirical foundation for the subsequent stages of our research programme. | URL: https://arxiv.org/pdf/2509.17548 ||| 4. T칤tulo Original: From OCL to JSX: declarative constraint modeling in modern SaaS tools | Categor칤a: Software Engineering | Descripci칩n: Abstract:The rise of this http URL in 2010, followed by frameworks like Angular, React, and this http URL, has accelerated the growth of low code development platforms. These platforms harness modern UIX paradigms, component-based architectures, and the SaaS model to enable non-experts to build software. The widespread adoption of single-page applications (SPAs), driven by these frameworks, has shaped low-code tools to deliver responsive, client side experiences. In parallel, many modeling platforms have moved to the cloud, adopting either server-centric architectures (e.g., GSLP) or client-side intelligence via SPA frameworks, anchoring core components in JavaScript or TypeScript. Within this context, this http URL, a JavaScript-based implementation of the Object Constraint Language, offers a web aligned approach to model validation, yet faces challenges such as partial standard coverage, limited adoption, and weak integration with modern front-end toolchains. In this paper, we explore JSX, a declarative, functional subset of JavaScript/TypeScript used in the React ecosystem, as an alternative to constraint expression in SaaS-based modeling environments. Its component-oriented structure supports inductive definitions for syntax, code generation, and querying. Through empirical evaluation, we compare JSX-based constraints with this http URL across representative modeling scenarios. Results show JSX provides broader expressiveness and better fits front-end-first architectures, indicating a promising path for constraint specification in modern modeling tools. | URL: https://arxiv.org/pdf/2509.17629 ||| 5. T칤tulo Original: Diagnosing Violations of State-based Specifications in iCFTL | Categor칤a: Software Engineering | Descripci칩n: Abstract:As modern software systems grow in complexity and operate in dynamic environments, the need for runtime analysis techniques becomes a more critical part of the verification and validation process. Runtime verification monitors the runtime system behaviour by checking whether an execution trace - a sequence of recorded events - satisfies a given specification, yielding a Boolean or quantitative verdict. However, when a specification is violated, such a verdict is often insufficient to understand why the violation happened. To fill this gap, diagnostics approaches aim to produce more informative verdicts. In this paper, we address the problem of generating informative verdicts for violated Inter-procedural Control-Flow Temporal Logic (iCFTL) specifications that express constraints over program variable values. We propose a diagnostic approach based on backward data-flow analysis to statically determine the relevant statements contributing to the specification violation. Using this analysis, we instrument the program to produce enriched execution traces. Using the enriched execution traces, we perform the runtime analysis and identify the statements whose execution led to the specification violation. We implemented our approach in a prototype tool, iCFTL-Diagnostics, and evaluated it on 112 specifications across 10 software projects. Our tool achieves 90% precision in identifying relevant statements for 100 of the 112 specifications. It reduces the number of lines that have to be inspected for diagnosing a violation by at least 90%. In terms of computational cost, iCFTL-Diagnostics generates a diagnosis within 7 min, and requires no more than 25 MB of memory. The instrumentation required to support diagnostics incurs an execution time overhead of less than 30% and a memory overhead below 20%. | URL: https://arxiv.org/pdf/2509.17776 ||| 6. T칤tulo Original: Toward Engineering AGI: Benchmarking the Engineering Design Capabilities of LLMs | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:Today, industry pioneers dream of developing general-purpose AI engineers capable of designing and building humanity's most ambitious projects--from starships that will carry us to distant worlds to Dyson spheres that harness stellar energy. Yet engineering design represents a fundamentally different challenge for large language models (LLMs) compared to traditional textbook-style problem solving or factual question answering. Real-world engineering design demands the synthesis of domain knowledge, navigation of complex trade-offs, and management of the tedious processes that consume much of practicing engineers' time. Despite these shared challenges across engineering disciplines, no benchmark currently captures the unique demands of engineering design work. In this work, we introduce ENGDESIGN, an Engineering Design benchmark that evaluates LLMs' abilities to perform practical design tasks across nine engineering domains: Operating System Design, Computer Architecture Design, Control System Design, Mechanical Systems, Structural Design, Digital Hardware Design, Analog Integrated Circuit Design, Robotics, and Signal Processing. Unlike existing benchmarks that focus on factual recall or question answering, ENGDESIGN uniquely emphasizes LLMs' ability to synthesize domain knowledge, reason under constraints, and generate functional, objective-oriented designs. Each task in ENGDESIGN represents a real-world engineering design problem, accompanied by a detailed task description specifying design goals, constraints, and performance requirements. We pioneer a simulation-based evaluation paradigm where LLM-generated designs undergo rigorous testing through executable, domain-specific simulations-from circuit SPICE simulations to structural finite element analysis, from control system validation to robotic motion planning. | URL: https://arxiv.org/pdf/2509.16204 ||| 7. T칤tulo Original: Deep Reinforcement Learning in Factor Investment | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:Deep reinforcement learning has shown promise in trade execution, yet its use in low-frequency factor portfolio construction remains under-explored. A key obstacle is the high-dimensional, unbalanced state space created by stocks that enter and exit the investable universe. We introduce Conditional Auto-encoded Factor-based Portfolio Optimisation (CAFPO), which compresses stock-level returns into a small set of latent factors conditioned on 94 firm-specific characteristics. The factors feed a DRL agent implemented with both PPO and DDPG to generate continuous long-short weights. On 20 years of U.S. equity data (2000--2020), CAFPO outperforms equal-weight, value-weight, Markowitz, vanilla DRL, and Fama--French-driven DRL, delivering a 24.6\% compound return and a Sharpe ratio of 0.94 out of sample. SHAP analysis further reveals economically intuitive factor attributions. Our results demonstrate that factor-aware representation learning can make DRL practical for institutional, low-turnover portfolio management. | URL: https://arxiv.org/pdf/2509.16206 ||| 8. T칤tulo Original: Predictive Machine Learning to Increase the Throughput of Container Yards | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:This study seeks to improve the throughput rates for shipping container terminals. In the United States, shipping ports link the domestic economy to global markets and are vital to sustain supply chain flow and economic stability. Maritime shipping accounts for nearly half of the U.S.'s annual international trade, two thirds of which are represented by container shipping. Previous studies highlighted the capability of automation in enhancing container processing; however, unlike in European and East Asian ports, full automation is limited in U.S. ports due to legal protections for human labor. Consequently, there is a need for alternative methods that deliver automation level efficiencies while maintaining the terms of cooperative agreements. This paper proposes an Intelligent Planning System (IPS) that applies the concept of Pareto Optimization to container yards through a mixed integer linear programming (MILP) based recursive appointment system. The results show an improvement from baseline for both daily terminal throughput volumes and processing times. The generated IPS can be employed to provide recommendations for container positioning and truck pickup appointments to optimize container yard layout and flow resulting in reduced realtime congestion and predictively mitigated future congestion. | URL: https://arxiv.org/pdf/2509.16207 ||| 9. T칤tulo Original: Synthesis of Service Life Prediction for Bridges in Texas | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:Design-build bridge contracts often include long-term service life requirements, but there are no clear technical guidelines or standardized methods to achieve or verify these goals. While durability practices are commonly applied, they lack quantitative validation. With many aging bridges and limited financial resources, accurately estimating remaining service life is essential for prioritizing repair and rehabilitation needs. This research reviews current practices and recent advancements in bridge service life prediction, providing practical guidance for evaluating and extending the lifespan of both existing and new structures. The findings support more efficient use of maintenance funds, better understanding of deterioration models and inspection methods, and informed strategies to ensure long-term structural performance. | URL: https://arxiv.org/pdf/2509.16208 ||| 10. T칤tulo Original: Scaling Digital Twin Models | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:In many industries, the scale and complexity of systems can present significant barriers to the development of accurate digital twin models. This paper introduces a novel methodology and a modular computational tool utilizing machine learning and dimensional analysis to establish a framework for scaling digital twin models. Scaling techniques have not yet been applied to digital twin technology, but they can eliminate the need for repetitive physical calibration of such models in industries where product lines include a variety of sizes of the same or similar products. In many cases, it may be easier or more cost-effective to perform physical calibration of the digital twin model on smaller units of a product line. Scaling techniques can then allow adapting the calibration data from the smaller units to other sizes of the product line without the need for additional data collection and experimentation for calibration. Conventional application of dimensional analysis for scaling in this context introduces several challenges due to distortion of scaling factors. This paper addresses these challenges and introduces a framework for proper scaling of digital twin models. The results are applied to scaling the models between an industrial-size wheel loader vehicle used in construction to a miniaturized system instrumented in a laboratory setting. | URL: https://arxiv.org/pdf/2509.16209"
"Resume los siguientes 10 papers cient칤ficos y devuelve la respuesta en formato JSON v치lido. Para cada paper traduce el t칤tulo al espa침ol y crea un objeto con los campos especificados. Usa emojis apropiados (游뱄 para IA, 游눹 para software, 游 para seguridad, 游빏 para investigaci칩n, etc.). IMPORTANTE: Responde 칔NICAMENTE con el JSON v치lido, sin texto adicional antes o despu칠s. Estructura JSON requerida: {""papers"": [{""titulo_espa침ol"": ""游댧 [emoji apropiado] T칤tulo traducido"", ""categoria"": ""[emoji 游늭] Categor칤a del paper"", ""resumen"": ""[emoji 游닇] Resumen en m치ximo 3 l칤neas"", ""puntos_clave"": ""[emoji 游꿢] Aspectos m치s importantes"", ""enlace"": ""[emoji 游댕] URL del paper""}, ...]} A continuaci칩n vienen los papers: 1. T칤tulo Original: Strain localization in reduced order asymptotic homogenization | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:A reduced order asymptotic homogenization based multiscale technique which can capture damage and inelastic effects in composite materials is proposed. This technique is based on two scale homogenization procedure where eigen strain representation accounts for the inelastic response and the computational efforts are alleviated by reduction of order technique. Macroscale stress is derived by calculating the influence tensors from the analysis of representative volume element (RVE). At microscale, the damage in the material is modeled using continuum damage mechanics (CDM) based framework. To solve the problem of strain localization a method of the alteration of stress-strain relation of micro con- stituents based on the dissipated fracture energy in a crack band is implemented. The issue of spurious post failure artificial stiffness at macroscale is discussed and effect of increasing the order to alleviate this problem is checked. Verification studies demonstrated the proposed formulation predicts the macroscale response and also captures the damage and plasticity induced inelastic strains. | URL: https://arxiv.org/pdf/2509.16210 ||| 2. T칤tulo Original: E | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:This paper describes a novel homogenization methodology for analyzing the failure of elastoplastic composite materials based on elastic and eigen influence tensors-driven transformation field analysis (E^2E^2-TFA). The proposed technique considers the microscopic eigenstrain field accounting for intra-phase damage and inelastic strains. This results in realistic computations by alleviating the post-damage stiffness response, which is a drawback of TFA-based methods. We attain computational efficiency by identifying the preprocessing data solely from the elastic and eigen transformation functions and adopting a reduced order modelling technique with a piecewise constant eigenstrain field throughout the subdomains. The performance of the model is assessed by simulating the response for (a) the representative volume element (RVE) as a homogenized continuum and (b) the various composites under complex load histories with intricate macroscale morphologies. Furthermore, the nonlinear shear stress-strain response of a glass fiber composite is calculated and compared to experimentally measured fracture initiation parameters, failure plane orientation, and strain histories. Finally, we show that E^2E^2-TFA can accurately and efficiently capture damage and inelastic deformations in order to estimate the mechanical response of composite materials in a better way. | URL: https://arxiv.org/pdf/2509.16211 ||| 3. T칤tulo Original: An efficient framework for computing sensitivity of modal-related structural dynamic characteristics with multi-parameters | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:The sensitivity of structural dynamic characteristics related to eigenmode (such as modal assurance criteria, modal flexibility, and modal mass etc.) has become a crucial and widely applied tool across various engineering fields. In this paper, a novel strategy is proposed for solving the sensitivity of structural dynamic characteristics related to eigenmode with respect to multiple variables. First, an algebraic method for computing the sensitivity of eigenvectors is developed to simplify the expression for sensitivity calculations. Subsequently, based on this new expression for eigenmode sensitivity, a framework for sensitivity analysis of structural dynamic characteristics related to eigenmodes with multiple parameters is established. With the incorporation of a preconditioning iterative method, the new computational framework effectively enhances the computational efficiency of sensitivity analysis for structural characteristics related to eigenmodes with multiple parameters. This framework is easy to operate and effectively reduces the ""Fill-in"" operations of sparse matrices. Three numerical examples are given to illustrate the effectiveness of the algorithm. The result shows that the novel strategy can significantly reduce central processing unit (CPU) computational time. | URL: https://arxiv.org/pdf/2509.16214 ||| 4. T칤tulo Original: On the Detection of Internal Defects in Structured Media | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:A critical issue that affects engineers trying to assess the structural integrity of various infrastructures, such as metal rods or acoustic ducts, is the challenge of detecting internal fractures (defects). Traditionally, engineers depend on audible and visual aids to identify these fractures, as they do not physically dissect the object in question into multiple pieces to check for inconsistencies. This research introduces ideas towards the development of a robust strategy to image such defects using only a small set of minimal, non-invasive measurements. Assuming a one dimensional model (e.g. longitudinal waves in long and thin rods/acoustic ducts or transverse vibrations of strings), we make use of the continuous one-dimensional wave equation to model these physical phenomena and then employ specialized mathematical analysis tools (the Laplace transform and optimization) to introduce our defect imaging ideas. In particular, we will focus on the case of a long bar which is homogeneous throughout except in a small area where a defect in its Young's modulus is present. We will first demonstrate how the problem is equivalent to a spring-mass vibrational system, and then show how our imaging strategy makes use of the Laplace domain analytic map between the characteristics of the respective defect and the measurement data. More explicitly, we will utilize MATLAB (a platform for numerical computations) to collect synthetic data (computational alternative to real world measurements) for several scenarios with one defect of arbitrary location and stiffness. Subsequently, we will use this data along with our analytically developed map (between defect characteristics and measurements) to construct a residual function which, once optimized, will reveal the location and magnitude of the stiffness defect. | URL: https://arxiv.org/pdf/2509.16216 ||| 5. T칤tulo Original: An Efficient Transient Nonlinear Circuit Simulator Using Exponential Integration and Block-Jacobi Precondition | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:Transient simulation of linear and nonlinear circuits remains an important task in modern EDA tools. At present, SPICE-like simulators face challenges in parallelization, nonlinear convergence and linear efficiency, especially when applied to large-scale circuits. To address the limitations of simulators in handling various nonlinear circuits, we adopt a generalized row-echelon regularization approach, which extends the applicability of exponential integrators to a broader class of differential algebraic equations. The proposed method employs matrix exponential vector products to integrate the regularized system, allowing for a larger time step size while preserving accuracy and stability. Furthermore, in order to accelerate GMRES-based solvers within Newton-Raphson iterations, a structured block-Jacobi preconditioner is designed for linear systems. For locally coupled circuits, Additive Schwarz overlapping strategy is adopted to enhance the solution performance. Numerical experiments of various nonlinear circuit models show that under same hardware environment, our method achieves a speedup of 1.95\times\times-- 3.27\times\times in total computation time compared to Backward Euler with Inexact Newton iterations, and time steps have decreased by an average of 60.70\% (up to 74.59\%). Compared with EI-NK method, total computing time of our method has a speedup of 1.08\times\times-- 1.79\times\times. These results highlight the potential of proposed method for scalable and nonlinear circuit simulation. | URL: https://arxiv.org/pdf/2509.16219 ||| 6. T칤tulo Original: An Open Dataset for Temperature Modelling in Machine Tools | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:This data set descriptor introduces a structured, high-resolution dataset of transient thermal simulations for a vertical axis of a machine tool test rig. The data set includes temperature and heat flux values recorded at 29 probe locations at 1800 time steps, sampled every second over a 30-minute range, across 17 simulation runs derived from a fractional factorial design. First, a computer-aided design model was de-featured, segmented, and optimized, followed by finite element (FE) modelling. Detailed information on material, mesh, and boundary conditions is included. To support research and model development, the dataset provides summary statistics, thermal evolution plots, correlation matrix analyses, and a reproducible Jupyter notebook. The data set is designed to support machine learning and deep learning applications in thermal modelling for prediction, correction, and compensation of thermally induced deviations in mechanical systems, and aims to support researchers without FE expertise by providing ready-to-use simulation data. | URL: https://arxiv.org/pdf/2509.16222 ||| 7. T칤tulo Original: Increasing Inter-Fiber Contact in the Altendorf-Jeulin Model | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:In fields such as material design or biomedicine, fiber materials play an important role. Fiber simulations, also called digital twins, provide a basis for testing and optimizing the material's physical behavior digitally. Inter-fiber contacts can influence the thermal and mechanical behavior of a fiber system; to our knowledge, however, there exist no parametric fiber models allowing for explicit modeling of the number of inter-fiber contacts. Therefore, this paper proposes an extension of the iterative force-biased fiber packing by Altendorf \& Jeulin. In this extension, we model the inter-fiber contacts explicitly and add another force to the force-biased packing to increase the number of contacts. We successfully validate the packing with respect to its parameter accuracy. Moreover, we show that the extension indeed increases the number of contacts, even exceeding theoretical values. Hence, this packing scheme has the potential to achieve higher accuracy in physical simulations. | URL: https://arxiv.org/pdf/2509.16225 ||| 8. T칤tulo Original: Learn to Rank Risky Investors: A Case Study of Predicting Retail Traders' Behaviour and Profitability | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:Identifying risky traders with high profits in financial markets is crucial for market makers, such as trading exchanges, to ensure effective risk management through real-time decisions on regulation compliance and hedging. However, capturing the complex and dynamic behaviours of individual traders poses significant challenges. Traditional classification and anomaly detection methods often establish a fixed risk boundary, failing to account for this complexity and dynamism. To tackle this issue, we propose a profit-aware risk ranker (PA-RiskRanker) that reframes the problem of identifying risky traders as a ranking task using Learning-to-Rank (LETOR) algorithms. Our approach features a Profit-Aware binary cross entropy (PA-BCE) loss function and a transformer-based ranker enhanced with a self-cross-trader attention pipeline. These components effectively integrate profit and loss (P&L) considerations into the training process while capturing intra- and inter-trader relationships. Our research critically examines the limitations of existing deep learning-based LETOR algorithms in trading risk management, which often overlook the importance of P&L in financial scenarios. By prioritising P&L, our method improves risky trader identification, achieving an 8.4% increase in F1 score compared to state-of-the-art (SOTA) ranking models like Rankformer. Additionally, it demonstrates a 10%-17% increase in average profit compared to all benchmark models. | URL: https://arxiv.org/pdf/2509.16616 ||| 9. T칤tulo Original: Rational Multi-Modal Transformers for TCR-pMHC Prediction | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:T cell receptor (TCR) recognition of peptide-MHC (pMHC) complexes is fundamental to adaptive immunity and central to the development of T cell-based immunotherapies. While transformer-based models have shown promise in predicting TCR-pMHC interactions, most lack a systematic and explainable approach to architecture design. We present an approach that uses a new post-hoc explainability method to inform the construction of a novel encoder-decoder transformer model. By identifying the most informative combinations of TCR and epitope sequence inputs, we optimize cross-attention strategies, incorporate auxiliary training objectives, and introduce a novel early-stopping criterion based on explanation quality. Our framework achieves state-of-the-art predictive performance while simultaneously improving explainability, robustness, and generalization. This work establishes a principled, explanation-driven strategy for modeling TCR-pMHC binding and offers mechanistic insights into sequence-level binding behavior through the lens of deep learning. | URL: https://arxiv.org/pdf/2509.17305 ||| 10. T칤tulo Original: MIND: Insightful Multi-subject Invariant Neural Decoding | Categor칤a: Computational Engineering, Finance, and Science | Descripci칩n: Abstract:Decoding visual signals holds the tantalizing potential to unravel the complexities of cognition and perception. While recent studies have focused on reconstructing visual stimuli from neural recordings to bridge brain activity with visual imagery, existing methods offer limited insights into the underlying mechanisms of visual processing in the brain. To mitigate this gap, we present an insightful Multi-subject Invariant Neural Decoding (iiMIND) model, which employs a novel dual-decoding framework--both biometric and semantic decoding--to offer neural interpretability in a data-driven manner and deepen our understanding of brain-based visual functionalities. Our iiMIND model operates through three core steps: establishing a shared neural representation space across subjects using a ViT-based masked autoencoder, disentangling neural features into complementary subject-specific and object-specific components, and performing dual decoding to support both biometric and semantic classification tasks. Experimental results demonstrate that iiMIND achieves state-of-the-art decoding performance with minimal scalability limitations. Furthermore, iiMIND empirically generates voxel-object activation fingerprints that reveal object-specific neural patterns and enable investigation of subject-specific variations in attention to identical stimuli. These findings provide a foundation for more interpretable and generalizable subject-invariant neural decoding, advancing our understanding of the voxel semantic selectivity as well as the neural vision processing dynamics. | URL: https://arxiv.org/pdf/2509.17313"
